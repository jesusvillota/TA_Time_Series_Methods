{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fbb5639",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 20px; text-align: center; border-bottom: 2px solid #e5e7eb;\">\n",
    "  <a href=\"1_2_arma_models.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: linear-gradient(180deg, #38549c 0%, #14276c 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; box-shadow: 0 4px 12px rgba(56,84,156,0.3); margin-right: 10px;\">\n",
    "    ‚Üê Session 1: ARMA Models\n",
    "  </a>\n",
    "  <a href=\"2_3_gdp_gdi.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: linear-gradient(180deg, #38549c 0%, #14276c 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; box-shadow: 0 4px 12px rgba(56,84,156,0.3);\">\n",
    "    GDP and GDI Analysis ‚Üí\n",
    "  </a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05430fd",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 880px; margin: 20px auto 22px; padding: 0px; border-radius: 18px; border: 1px solid #e5e7eb; background: linear-gradient(180deg, #ffffff 0%, #f9fafb 100%); box-shadow: 0 8px 26px rgba(0,0,0,0.06); overflow: hidden;\">\n",
    "\n",
    "  <!-- Banner Header -->\n",
    "  <div style=\"padding: 34px 32px 14px; text-align: center; line-height: 1.38;\">\n",
    "    <div style=\"font-size: 13px; letter-spacing: 0.14em; text-transform: uppercase; color: #6b7280; font-weight: bold; margin-bottom: 5px;\">\n",
    "      Session #2 ‚Ä¢ Part 1\n",
    "    </div>\n",
    "    <div style=\"font-size: 29px; font-weight: 800; color: #14276c; margin-bottom: 4px;\">\n",
    "      Multivariate time series, Volatility modelling and Kalman filtering simulations\n",
    "    </div>\n",
    "    <div style=\"font-size: 16.5px; color: #374151; font-style: italic; margin-bottom: 0;\">\n",
    "      Advanced Training School: Methods for Time Series\n",
    "    </div>\n",
    "  </div>\n",
    "\n",
    "  <!-- Logo Section -->\n",
    "  <div style=\"background: none; text-align: center; margin: 30px 0 10px;\">\n",
    "    <img src=\"https://www.cemfi.es/images/Logo-Azul.png\" alt=\"CEMFI Logo\" style=\"width: 158px; filter: drop-shadow(0 2px 12px rgba(56,84,156,0.05)); margin-bottom: 0;\">\n",
    "  </div>\n",
    "\n",
    "  <!-- Name -->\n",
    "  <div style=\"font-family: 'Times New Roman', Times, serif; color: #38549c; text-align: center; font-size: 1.22em; font-weight: bold; margin-bottom: 0px;\">\n",
    "    Jesus Villota Miranda ¬© 2025\n",
    "  </div>\n",
    "\n",
    "  <!-- Contact info -->\n",
    "  <div style=\"font-family: 'Times New Roman', Times, serif; color: #38549c; text-align: center; font-size: 1em; margin-top: 7px; margin-bottom: 20px;\">\n",
    "    <a href=\"mailto:jesus.villota@cemfi.edu.es\" style=\"color: #38549c; text-decoration: none; margin-right:8px;\" title=\"Email\">\n",
    "      jesus.villota@cemfi.edu.es\n",
    "    </a>\n",
    "    <span style=\"color:#9fa7bd;\">|</span>\n",
    "    <a href=\"https://www.linkedin.com/in/jesusvillotamiranda/\" target=\"_blank\" style=\"color: #38549c; text-decoration: none; margin-left:7px;\" title=\"LinkedIn\">\n",
    "      LinkedIn\n",
    "    </a>\n",
    "  </div>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f952f653",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 24px 32px; border-radius: 18px; border: 1px solid #e5e7eb; background: linear-gradient(180deg, #ffffff 0%, #f9fafb 100%); box-shadow: 0 8px 26px rgba(0,0,0,0.06);\">\n",
    "\n",
    "<div style=\"font-size: 22px; font-weight: 700; color: #14276c; margin-bottom: 16px; text-align: center;\">\n",
    "  Table of Contents\n",
    "</div>\n",
    "\n",
    "<div style=\"font-size: 15px; color: #374151; line-height: 1.8;\">\n",
    "  <div style=\"margin-bottom: 12px;\"><strong>1.</strong> <a href=\"#section-1\" style=\"color: #38549c; text-decoration: none;\">Multivariate Time Series Models</a></div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">1.1 Vector Autoregression (VAR)</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">1.2 VAR with Impulse Response Functions</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">1.3 Vector Error Correction Model (VECM)</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 12px; font-size: 14px;\">1.4 Multivariate ARMA</div>\n",
    "  <div style=\"margin-bottom: 12px;\"><strong>2.</strong> <a href=\"#section-2\" style=\"color: #38549c; text-decoration: none;\">Volatility Modeling</a></div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.1 ARCH Models</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.2 GARCH Models</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 12px; font-size: 14px;\">2.3 Multivariate GARCH</div>\n",
    "  <div style=\"margin-bottom: 0px;\"><strong>3.</strong> <a href=\"#section-3\" style=\"color: #38549c; text-decoration: none;\">Kalman Filter Simulations</a></div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">3.1 Basic Kalman Filter</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">3.2 AR(1) with Measurement Error</div>\n",
    "  <div style=\"margin-left: 20px; margin-bottom: 0px; font-size: 14px;\">3.3 Time-Varying Parameter Model</div>\n",
    "</div>\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a270a613",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"../notebook_styles.css\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b219a43",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"../notebook_styles.css\">\n",
    "\n",
    "<a id=\"section-1\"></a>\n",
    "<h2 class=\"styled-header\">1) Multivariate Time Series Models</h2>\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç Conceptual Foundation**: **Multivariate time series models** extend univariate models to capture **dynamic interdependencies** between multiple variables. Unlike univariate models that describe a single variable's evolution, multivariate models allow us to understand how variables interact, how shocks propagate across the system, and how long-run relationships (cointegration) emerge from short-run dynamics.\n",
    "\n",
    "</div>\n",
    "\n",
    "Multivariate models are essential in economics and finance because:\n",
    "- **Economic variables are interconnected**: GDP affects unemployment, interest rates affect exchange rates, stock prices affect bond yields\n",
    "- **Policy analysis requires system-wide thinking**: Central bank actions affect multiple markets simultaneously\n",
    "- **Forecasting benefits from cross-variable information**: Knowing one variable helps predict others\n",
    "\n",
    "**Key Multivariate Models**:\n",
    "1. **VAR (Vector Autoregression)**: Captures dynamic feedback between variables\n",
    "2. **VECM (Vector Error Correction Model)**: Models cointegrated variables with error correction\n",
    "3. **VARMA**: Combines VAR and VMA components for richer dynamics\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Why This Matters**: Multivariate models reveal the **structure of economic relationships**. They allow us to answer questions like: \"If the central bank raises interest rates, how does this affect GDP, inflation, and exchange rates over time?\" This is impossible with univariate models alone.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144ce7b",
   "metadata": {},
   "source": [
    "### 1.1 Vector Autoregression (VAR)\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate a bivariate VAR(1) process to demonstrate how variables interact dynamically. We'll show how shocks in one variable affect both variables over time, creating a system of interdependent equations.\n",
    "\n",
    "</div>\n",
    "\n",
    "The **Vector Autoregression of order 1** (VAR(1)) is defined as:\n",
    "\n",
    "$$\\mathbf{y}_t = \\mathbf{c} + \\mathbf{\\Phi}_1 \\mathbf{y}_{t-1} + \\mathbf{u}_t$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{y}_t = (y_{1t}, y_{2t})'$ is a $2 \\times 1$ vector of variables\n",
    "- $\\mathbf{c} = (c_1, c_2)'$ is a $2 \\times 1$ vector of intercepts\n",
    "- $\\mathbf{\\Phi}_1$ is a $2 \\times 2$ matrix of coefficients:\n",
    "  $$\\mathbf{\\Phi}_1 = \\begin{pmatrix} \\phi_{11} & \\phi_{12} \\\\ \\phi_{21} & \\phi_{22} \\end{pmatrix}$$\n",
    "- $\\mathbf{u}_t = (u_{1t}, u_{2t})'$ is a $2 \\times 1$ vector of innovations with covariance matrix $\\mathbf{\\Sigma}$\n",
    "\n",
    "**Expanded Form**:\n",
    "\n",
    "The VAR(1) can be written as two equations:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "y_{1t} &= c_1 + \\phi_{11} y_{1,t-1} + \\phi_{12} y_{2,t-1} + u_{1t} \\\\\n",
    "y_{2t} &= c_2 + \\phi_{21} y_{1,t-1} + \\phi_{22} y_{2,t-1} + u_{2t}\n",
    "\\end{aligned}$$\n",
    "\n",
    "**Key Properties**:\n",
    "\n",
    "1. **Cross-Variable Dependencies**: \n",
    "   - $\\phi_{12}$ captures how $y_2$ affects $y_1$ (Granger causality from $y_2$ to $y_1$)\n",
    "   - $\\phi_{21}$ captures how $y_1$ affects $y_2$ (Granger causality from $y_1$ to $y_2$)\n",
    "   - Both can be non-zero, creating **feedback** between variables\n",
    "\n",
    "2. **Stationarity Condition**: The VAR(1) is stationary if all eigenvalues of $\\mathbf{\\Phi}_1$ lie inside the unit circle (modulus $< 1$). This is equivalent to:\n",
    "   $$\\det(\\mathbf{I} - \\mathbf{\\Phi}_1 z) \\neq 0 \\quad \\text{for } |z| \\leq 1$$\n",
    "\n",
    "3. **Innovation Covariance**: The innovations $\\mathbf{u}_t$ have covariance matrix:\n",
    "   $$\\mathbf{\\Sigma} = \\begin{pmatrix} \\sigma_1^2 & \\sigma_{12} \\\\ \\sigma_{12} & \\sigma_2^2 \\end{pmatrix}$$\n",
    "   where $\\sigma_{12}$ is the contemporaneous covariance between innovations.\n",
    "\n",
    "4. **Wold Representation**: Under stationarity, the VAR(1) has a moving average representation:\n",
    "   $$\\mathbf{y}_t = \\boldsymbol{\\mu} + \\sum_{j=0}^{\\infty} \\mathbf{\\Psi}_j \\mathbf{u}_{t-j}$$\n",
    "   where $\\boldsymbol{\\mu} = (\\mathbf{I} - \\mathbf{\\Phi}_1)^{-1} \\mathbf{c}$ is the unconditional mean, and $\\mathbf{\\Psi}_j$ are the impulse response matrices.\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: VAR models capture **simultaneous and lagged interdependencies**. Unlike univariate AR models that only depend on their own past, VAR models allow each variable to depend on the past of all variables in the system. This creates rich dynamics where shocks propagate through the system over multiple periods.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fdc1dfe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of observations (_N) was 0, now 1,000.\n",
      "\n",
      "\n",
      "\n",
      "Time variable: t, 1 to 1000\n",
      "        Delta: 1 unit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "\n",
      ". list t y1 y2 u1 u2 in 1/10  \n",
      "\n",
      "     +-----------------------------------------------+\n",
      "     |  t        y1       y2          u1          u2 |\n",
      "     |-----------------------------------------------|\n",
      "  1. |  1         0        0       .9592    1.258564 |\n",
      "  2. |  2   .098195   .21643    -.001805      .01643 |\n",
      "  3. |  3         .        .     .544077    .8469192 |\n",
      "  4. |  4         .        .    .0016287    .1625661 |\n",
      "  5. |  5         .        .    .3576809    1.069856 |\n",
      "     |-----------------------------------------------|\n",
      "  6. |  6         .        .    1.878868    .5853399 |\n",
      "  7. |  7         .        .    2.754746    2.741495 |\n",
      "  8. |  8         .        .   -.6125968   -1.679166 |\n",
      "  9. |  9         .        .    .1973079    .4947369 |\n",
      " 10. | 10         .        .    1.610224    2.350376 |\n",
      "     +-----------------------------------------------+\n",
      "\n",
      ". display \"Summary Statistics for VAR(1) Process:\"\n",
      "Summary Statistics for VAR(1) Process:\n",
      "\n",
      ". summarize y1 y2 u1 u2, detail  \n",
      "\n",
      "                             y1\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%            0              0\n",
      " 5%            0        .098195\n",
      "10%            0              .       Obs                   2\n",
      "25%            0              .       Sum of wgt.           2\n",
      "\n",
      "50%     .0490975                      Mean           .0490975\n",
      "                        Largest       Std. dev.      .0694343\n",
      "75%      .098195              .\n",
      "90%      .098195              .       Variance       .0048211\n",
      "95%      .098195              0       Skewness              0\n",
      "99%      .098195        .098195       Kurtosis              1\n",
      "\n",
      "                             y2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%            0              0\n",
      " 5%            0         .21643\n",
      "10%            0              .       Obs                   2\n",
      "25%            0              .       Sum of wgt.           2\n",
      "\n",
      "50%      .108215                      Mean            .108215\n",
      "                        Largest       Std. dev.      .1530391\n",
      "75%       .21643              .\n",
      "90%       .21643              .       Variance        .023421\n",
      "95%       .21643              0       Skewness              0\n",
      "99%       .21643         .21643       Kurtosis              1\n",
      "\n",
      "                             u1\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -2.421662      -3.355197\n",
      " 5%    -1.644919      -2.949293\n",
      "10%    -1.277207      -2.856949       Obs               1,000\n",
      "25%    -.6367267      -2.809036       Sum of wgt.       1,000\n",
      "\n",
      "50%     .0143557                      Mean           .0141333\n",
      "                        Largest       Std. dev.      1.020651\n",
      "75%     .7212854       2.812786\n",
      "90%     1.347114       2.863938       Variance       1.041728\n",
      "95%     1.626225       3.021777       Skewness      -.0410158\n",
      "99%     2.390601       3.653764       Kurtosis       3.140141\n",
      "\n",
      "                             u2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     -2.22826      -3.034917\n",
      " 5%    -1.588483      -2.860744\n",
      "10%      -1.2513      -2.850298       Obs               1,000\n",
      "25%     -.658851      -2.836802       Sum of wgt.       1,000\n",
      "\n",
      "50%     .0532249                      Mean           .0556206\n",
      "                        Largest       Std. dev.      .9990411\n",
      "75%     .6991647       2.741495\n",
      "90%     1.383859       2.746808       Variance       .9980832\n",
      "95%     1.733998       2.751901       Skewness       .0139092\n",
      "99%     2.281826        3.15228       Kurtosis       2.883512\n",
      "\n",
      ". correlate y1 y2  \n",
      "(obs=2)\n",
      "\n",
      "             |       y1       y2\n",
      "-------------+------------------\n",
      "          y1 |   1.0000\n",
      "          y2 |   1.0000   1.0000\n",
      "\n",
      "\n",
      ". cap noi twoway (line y1 t),     title(\"VAR(1): Variable y1_t\")     ytitle(\"y1_\n",
      "> t\") xtitle(\"Time\")     name(ts_var_y1, replace) \n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph0.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph0.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line y2 t),     title(\"VAR(1): Variable y2_t\")     ytitle(\"y2_\n",
      "> t\") xtitle(\"Time\")     name(ts_var_y2, replace) \n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph1.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph1.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line y1 t) (line y2 t),     title(\"VAR(1): Both Variables\")   \n",
      ">   ytitle(\"Value\") xtitle(\"Time\")     legend(label(1 \"y1_t\") label(2 \"y2_t\"))  \n",
      ">    name(ts_var_both, replace) \n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph2.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph2.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi ac y1, lags(20) name(acf_var_y1, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi ac y2, lags(20) name(acf_var_y2, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi xcorr y1 y2, lags(20) name(ccf_var, replace)\n",
      "lags() too large.  Must be less than -1\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"VAR(1) Parameters:\"\n",
      "VAR(1) Parameters:\n",
      "\n",
      ". display \"Phi_1 = [\" %6.4f phi11 \", \" %6.4f phi12 \"; \" %6.4f phi21 \", \" %6.4f p\n",
      "> hi22 \"]\"\n",
      "Phi_1 = [0.5000, 0.3000; 0.2000, 0.6000]\n",
      "\n",
      ". display \"c = [\" %6.4f c1 \"; \" %6.4f c2 \"]\"\n",
      "c = [0.1000; 0.2000]\n",
      "\n",
      ". display \"Innovation correlation = \" %6.4f rho\n",
      "Innovation correlation = 0.5000\n"
     ]
    }
   ],
   "source": [
    "* ============================================================================\n",
    "* Simulation 1: Vector Autoregression (VAR(1))\n",
    "* ============================================================================\n",
    "* Simulate bivariate VAR(1): y_t = c + Phi_1 * y_{t-1} + u_t\n",
    "* where y_t = (y1_t, y2_t)' is a 2x1 vector\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set VAR(1) parameters\n",
    "* Coefficient matrix Phi_1:\n",
    "*   [phi_11  phi_12]   [0.5   0.3]\n",
    "*   [phi_21  phi_22] = [0.2   0.6]\n",
    "scalar phi11 = 0.5  // Effect of y1_{t-1} on y1_t\n",
    "scalar phi12 = 0.3  // Effect of y2_{t-1} on y1_t\n",
    "scalar phi21 = 0.2  // Effect of y1_{t-1} on y2_t\n",
    "scalar phi22 = 0.6  // Effect of y2_{t-1} on y2_t\n",
    "\n",
    "* Intercept vector c = (c1, c2)'\n",
    "scalar c1 = 0.1  // Intercept for equation 1\n",
    "scalar c2 = 0.2  // Intercept for equation 2\n",
    "\n",
    "* Innovation covariance matrix Sigma:\n",
    "*   [sigma_1^2  sigma_12]   [1.0   0.5]\n",
    "*   [sigma_12   sigma_2^2] = [0.5   1.0]\n",
    "* This implies correlation = 0.5 / (1.0 * 1.0) = 0.5\n",
    "scalar sigma1 = 1.0  // Standard deviation of u1_t\n",
    "scalar sigma2 = 1.0  // Standard deviation of u2_t\n",
    "scalar sigma12 = 0.5  // Covariance between u1_t and u2_t\n",
    "\n",
    "* Generate correlated innovations u_t = (u1_t, u2_t)'\n",
    "* Method: Use Cholesky decomposition to generate correlated normal random variables\n",
    "* If L is the Cholesky factor of Sigma, then u = L * z where z ~ N(0,I)\n",
    "* Cholesky factor: L = [sigma1          0        ]\n",
    "*                      [sigma12/sigma1  sqrt(sigma2^2 - (sigma12/sigma1)^2)]\n",
    "\n",
    "scalar rho = sigma12 / (sigma1 * sigma2)  // Correlation coefficient\n",
    "scalar L11 = sigma1  // First element of Cholesky factor\n",
    "scalar L21 = sigma12 / sigma1  // Second row, first column\n",
    "scalar L22 = sqrt(sigma2^2 - (sigma12/sigma1)^2)  // Second row, second column\n",
    "\n",
    "* Generate independent standard normal random variables\n",
    "generate z1 = rnormal()  // Independent standard normal for innovation 1\n",
    "generate z2 = rnormal()  // Independent standard normal for innovation 2\n",
    "\n",
    "* Generate correlated innovations using Cholesky decomposition\n",
    "generate u1 = L11 * z1  // u1_t = L11 * z1_t\n",
    "generate u2 = L21 * z1 + L22 * z2  // u2_t = L21 * z1_t + L22 * z2_t\n",
    "\n",
    "* Initialize VAR(1) variables\n",
    "generate y1 = .  // Initialize y1 as missing\n",
    "generate y2 = .  // Initialize y2 as missing\n",
    "\n",
    "* Set initial conditions (start at unconditional mean)\n",
    "* Unconditional mean: mu = (I - Phi_1)^(-1) * c\n",
    "* For simplicity, start at zero\n",
    "replace y1 = 0 if t == 1  // Set initial condition y1_1 = 0\n",
    "replace y2 = 0 if t == 1  // Set initial condition y2_1 = 0\n",
    "\n",
    "* Generate lagged variables\n",
    "generate y1_lag1 = L.y1  // Create lag-1 of y1 (y1_{t-1})\n",
    "generate y2_lag1 = L.y2  // Create lag-1 of y2 (y2_{t-1})\n",
    "\n",
    "* Recursively generate VAR(1) process:\n",
    "* y1_t = c1 + phi11 * y1_{t-1} + phi12 * y2_{t-1} + u1_t\n",
    "* y2_t = c2 + phi21 * y1_{t-1} + phi22 * y2_{t-1} + u2_t\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {  // Loop from observation 2 to 1000\n",
    "        replace y1 = c1 + phi11 * y1_lag1 + phi12 * y2_lag1 + u1 if t == `i'\n",
    "        replace y2 = c2 + phi21 * y1_lag1 + phi22 * y2_lag1 + u2 if t == `i'\n",
    "        * Update lagged variables for next iteration\n",
    "        replace y1_lag1 = L.y1 if t == `i'\n",
    "        replace y2_lag1 = L.y2 if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Display first 10 observations\n",
    "list t y1 y2 u1 u2 in 1/10  // Display first 10 observations\n",
    "\n",
    "* Summary statistics\n",
    "display \"Summary Statistics for VAR(1) Process:\"\n",
    "summarize y1 y2 u1 u2, detail  // Display detailed summary statistics\n",
    "\n",
    "* Cross-correlation between y1 and y2\n",
    "correlate y1 y2  // Display correlation matrix\n",
    "\n",
    "* Time series plots\n",
    "twoway (line y1 t), ///\n",
    "    title(\"VAR(1): Variable y1_t\") ///\n",
    "    ytitle(\"y1_t\") xtitle(\"Time\") ///\n",
    "    name(ts_var_y1, replace) // Save graph\n",
    "\n",
    "twoway (line y2 t), ///\n",
    "    title(\"VAR(1): Variable y2_t\") ///\n",
    "    ytitle(\"y2_t\") xtitle(\"Time\") ///\n",
    "    name(ts_var_y2, replace) // Save graph\n",
    "\n",
    "* Overlay both series\n",
    "twoway (line y1 t) (line y2 t), ///\n",
    "    title(\"VAR(1): Both Variables\") ///\n",
    "    ytitle(\"Value\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"y1_t\") label(2 \"y2_t\")) ///\n",
    "    name(ts_var_both, replace) // Save graph\n",
    "\n",
    "* Autocorrelation functions\n",
    "ac y1, lags(20) name(acf_var_y1, replace)\n",
    "ac y2, lags(20) name(acf_var_y2, replace)\n",
    "\n",
    "* Cross-correlation function (CCF)\n",
    "xcorr y1 y2, lags(20) name(ccf_var, replace)\n",
    "\n",
    "display \"\"\n",
    "display \"VAR(1) Parameters:\"\n",
    "display \"Phi_1 = [\" %6.4f phi11 \", \" %6.4f phi12 \"; \" %6.4f phi21 \", \" %6.4f phi22 \"]\"\n",
    "display \"c = [\" %6.4f c1 \"; \" %6.4f c2 \"]\"\n",
    "display \"Innovation correlation = \" %6.4f rho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27d53db",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Dynamic Interdependencies**: The time series plots show that both `y1` and `y2` evolve together, reflecting their interdependence. When one variable moves, it affects the other through the cross-coefficients ($\\phi_{12}$ and $\\phi_{21}$).\n",
    "\n",
    "2. **Cross-Correlation Structure**: The cross-correlation function (CCF) reveals how `y1` and `y2` are related at different lags. Since $\\phi_{12} = 0.3 > 0$, past values of `y2` positively affect `y1`. Similarly, $\\phi_{21} = 0.2 > 0$ means past values of `y1` positively affect `y2`.\n",
    "\n",
    "3. **Autocorrelation Patterns**: Both variables show persistence (positive autocorrelation) because the diagonal elements ($\\phi_{11} = 0.5$ and $\\phi_{22} = 0.6$) are positive. The ACF decays gradually, similar to univariate AR processes, but the decay pattern is influenced by the full VAR system.\n",
    "\n",
    "4. **Innovation Correlation**: The contemporaneous correlation between innovations ($\\rho = 0.5$) means that shocks to `y1` and `y2` tend to occur together. This captures **simultaneous relationships** that cannot be explained by lagged values alone.\n",
    "\n",
    "5. **System Dynamics**: The VAR(1) creates a **feedback loop**: \n",
    "   - A shock to `y1` affects `y1` directly (through $\\phi_{11}$) and `y2` (through $\\phi_{21}$)\n",
    "   - The change in `y2` then feeds back to `y1` (through $\\phi_{12}$) in the next period\n",
    "   - This creates complex, multi-period dynamics that persist over time\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: VAR models capture both **direct effects** (how a variable's own past affects it) and **spillover effects** (how other variables' past affects it). This makes VAR models powerful tools for understanding system-wide dynamics, forecasting multiple variables simultaneously, and analyzing how shocks propagate through economic systems.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64158fbe",
   "metadata": {},
   "source": [
    "### 1.2 VAR with Impulse Response Functions (IRF)\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Compute and visualize Impulse Response Functions (IRFs) for the VAR(1) model. IRFs show how a one-time shock to one variable affects both variables over time, revealing the dynamic structure of the system.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Impulse Response Functions** answer the question: \"What happens to all variables in the system when we give a one-unit shock to variable $i$ at time $t$?\"\n",
    "\n",
    "**Mathematical Framework**:\n",
    "\n",
    "Starting from the VAR(1) representation:\n",
    "\n",
    "$$\\mathbf{y}_t = \\mathbf{c} + \\mathbf{\\Phi}_1 \\mathbf{y}_{t-1} + \\mathbf{u}_t$$\n",
    "\n",
    "Under stationarity, we can write the **Wold representation** (moving average form):\n",
    "\n",
    "$$\\mathbf{y}_t = \\boldsymbol{\\mu} + \\sum_{j=0}^{\\infty} \\mathbf{\\Psi}_j \\mathbf{u}_{t-j}$$\n",
    "\n",
    "where:\n",
    "- $\\boldsymbol{\\mu} = (\\mathbf{I} - \\mathbf{\\Phi}_1)^{-1} \\mathbf{c}$ is the unconditional mean\n",
    "- $\\mathbf{\\Psi}_j$ are the **impulse response matrices** that show the effect of a shock $j$ periods ago\n",
    "\n",
    "**Impulse Response Matrix**:\n",
    "\n",
    "The $(i,k)$ element of $\\mathbf{\\Psi}_j$, denoted $\\psi_{ik}(j)$, measures the response of variable $i$ at time $t+j$ to a one-unit shock to variable $k$ at time $t$:\n",
    "\n",
    "$$\\psi_{ik}(j) = \\frac{\\partial y_{i,t+j}}{\\partial u_{kt}}$$\n",
    "\n",
    "**Orthogonalized vs. Non-Orthogonalized IRFs**:\n",
    "\n",
    "1. **Non-Orthogonalized IRFs**: Use the original innovations $\\mathbf{u}_t$, which may be correlated. This means a shock to one variable is typically accompanied by correlated shocks to other variables.\n",
    "\n",
    "2. **Orthogonalized IRFs**: Use **Cholesky decomposition** to create orthogonal shocks. If $\\mathbf{\\Sigma} = \\mathbf{P}\\mathbf{P}'$ (Cholesky decomposition), then $\\mathbf{v}_t = \\mathbf{P}^{-1}\\mathbf{u}_t$ are orthogonal innovations with identity covariance matrix. The orthogonalized IRF is:\n",
    "   $$\\mathbf{\\Psi}_j^o = \\mathbf{\\Psi}_j \\mathbf{P}$$\n",
    "\n",
    "**Cholesky Ordering**:\n",
    "\n",
    "The Cholesky decomposition requires an **ordering assumption**:\n",
    "- Variables ordered first are assumed to affect others **contemporaneously**\n",
    "- Variables ordered later only affect others with a **lag**\n",
    "- This ordering can have economic interpretation (e.g., monetary policy affects markets immediately, but markets affect policy with a lag)\n",
    "\n",
    "**Cumulative IRFs**:\n",
    "\n",
    "The **cumulative impulse response** sums up the effects over time:\n",
    "\n",
    "$$\\mathbf{\\Psi}^C(h) = \\sum_{j=0}^{h} \\mathbf{\\Psi}_j$$\n",
    "\n",
    "This shows the **total long-run effect** of a shock after $h$ periods.\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: IRFs are the **signature of a VAR model**‚Äîthey reveal how shocks propagate through the system. They are essential for:\n",
    "- **Policy analysis**: Understanding the dynamic effects of policy interventions\n",
    "- **Forecasting**: Knowing how shocks affect future values\n",
    "- **Model validation**: Checking if IRF patterns match economic intuition\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecedaf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "insufficient observations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r(2001);\n",
      "r(2001);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "* ============================================================================\n",
    "* Simulation 2: VAR with Impulse Response Functions\n",
    "* ============================================================================\n",
    "* Compute IRFs for the VAR(1) model from Simulation 1\n",
    "* We'll compute both non-orthogonalized and orthogonalized IRFs\n",
    "\n",
    "* Use the VAR(1) data from Simulation 1 (assumes we're continuing from previous simulation)\n",
    "* If running separately, re-run Simulation 1 first\n",
    "\n",
    "* Estimate VAR(1) model using Stata's var command\n",
    "var y1 y2, lags(1)  // Estimate VAR(1) model\n",
    "\n",
    "* Create IRF set\n",
    "irf create var1, step(20) set(myirf) replace  // Create IRF set with 20 periods ahead\n",
    "\n",
    "* Display IRF results\n",
    "irf graph irf, impulse(y1) response(y1)  // IRF of y1 to shock in y1\n",
    "irf graph irf, impulse(y1) response(y2)  // IRF of y2 to shock in y1\n",
    "irf graph irf, impulse(y2) response(y1)  // IRF of y1 to shock in y2\n",
    "irf graph irf, impulse(y2) response(y2)  // IRF of y2 to shock in y2\n",
    "\n",
    "* Orthogonalized IRFs (using Cholesky decomposition)\n",
    "* Default ordering: y1, y2 (y1 affects y2 contemporaneously)\n",
    "irf graph oirf, impulse(y1) response(y1)  // Orthogonalized IRF: y1 -> y1\n",
    "irf graph oirf, impulse(y1) response(y2)  // Orthogonalized IRF: y1 -> y2\n",
    "irf graph oirf, impulse(y2) response(y1)  // Orthogonalized IRF: y2 -> y1\n",
    "irf graph oirf, impulse(y2) response(y2)  // Orthogonalized IRF: y2 -> y2\n",
    "\n",
    "* Cumulative IRFs\n",
    "irf graph cirf, impulse(y1) response(y1)  // Cumulative IRF: y1 -> y1\n",
    "irf graph cirf, impulse(y1) response(y2)  // Cumulative IRF: y1 -> y2\n",
    "irf graph cirf, impulse(y2) response(y1)  // Cumulative IRF: y2 -> y1\n",
    "irf graph cirf, impulse(y2) response(y2)  // Cumulative IRF: y2 -> y2\n",
    "\n",
    "* Alternative: Manual computation of IRFs\n",
    "* For VAR(1): Psi_0 = I, Psi_j = Phi_1^j for j >= 1\n",
    "* We can compute this manually to verify\n",
    "\n",
    "* Store coefficient matrix from VAR estimation\n",
    "matrix Phi1 = e(A)  // Extract coefficient matrix from VAR estimation\n",
    "matrix list Phi1  // Display coefficient matrix\n",
    "\n",
    "* Compute IRF matrices manually\n",
    "matrix Psi0 = I(2)  // Psi_0 = Identity matrix\n",
    "matrix Psi1 = Phi1  // Psi_1 = Phi_1\n",
    "matrix Psi2 = Phi1 * Phi1  // Psi_2 = Phi_1^2\n",
    "matrix Psi3 = Phi1 * Psi2  // Psi_3 = Phi_1^3\n",
    "\n",
    "display \"\"\n",
    "display \"Impulse Response Matrices (first 4 periods):\"\n",
    "display \"Psi_0 (contemporaneous):\"\n",
    "matrix list Psi0\n",
    "display \"Psi_1 (1 period ahead):\"\n",
    "matrix list Psi1\n",
    "display \"Psi_2 (2 periods ahead):\"\n",
    "matrix list Psi2\n",
    "display \"Psi_3 (3 periods ahead):\"\n",
    "matrix list Psi3\n",
    "\n",
    "* Compute Cholesky decomposition of innovation covariance matrix\n",
    "matrix Sigma = e(Sigma)  // Extract innovation covariance matrix\n",
    "matrix P = cholesky(Sigma)  // Cholesky decomposition: Sigma = P * P'\n",
    "matrix list P  // Display Cholesky factor\n",
    "\n",
    "* Orthogonalized IRF matrices\n",
    "matrix Oirf0 = Psi0 * P  // Orthogonalized Psi_0\n",
    "matrix Oirf1 = Psi1 * P  // Orthogonalized Psi_1\n",
    "matrix Oirf2 = Psi2 * P  // Orthogonalized Psi_2\n",
    "\n",
    "display \"\"\n",
    "display \"Orthogonalized Impulse Response Matrices:\"\n",
    "display \"OIRF_0:\"\n",
    "matrix list Oirf0\n",
    "display \"OIRF_1:\"\n",
    "matrix list Oirf1\n",
    "display \"OIRF_2:\"\n",
    "matrix list Oirf2\n",
    "\n",
    "display \"\"\n",
    "display \"IRF Interpretation:\"\n",
    "display \"The (i,j) element shows the response of variable i to a shock in variable j\"\n",
    "display \"Orthogonalized IRFs assume shocks are uncorrelated (via Cholesky ordering)\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8daf4228",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Dynamic Response Patterns**: The IRF plots show how shocks propagate through the system:\n",
    "   - **Own-shock effects**: A shock to `y1` affects `y1` itself, with the effect decaying over time (due to stationarity)\n",
    "   - **Cross-shock effects**: A shock to `y1` also affects `y2`, and vice versa, demonstrating the interdependence\n",
    "\n",
    "2. **Persistence**: The IRFs decay gradually because the VAR(1) is stationary. The rate of decay depends on the eigenvalues of $\\mathbf{\\Phi}_1$. If eigenvalues are close to 1, effects persist longer.\n",
    "\n",
    "3. **Orthogonalized vs. Non-Orthogonalized**: \n",
    "   - **Non-orthogonalized IRFs** show responses to correlated shocks (as they occur in the data)\n",
    "   - **Orthogonalized IRFs** show responses to uncorrelated shocks, making it easier to isolate the effect of a single variable's shock\n",
    "   - The difference between them reflects the **contemporaneous correlation** in innovations\n",
    "\n",
    "4. **Cumulative Effects**: Cumulative IRFs show the **total long-run impact** of a shock. For stationary VARs, cumulative IRFs converge to a finite value, representing the permanent effect (if any).\n",
    "\n",
    "5. **Cholesky Ordering**: The orthogonalized IRFs depend on the ordering assumption. In our example with ordering (y1, y2):\n",
    "   - A shock to `y1` affects `y2` **immediately** (contemporaneously)\n",
    "   - A shock to `y2` only affects `y1` with a **lag** (next period)\n",
    "   - This asymmetry reflects the identification assumption\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-left: 4px solid #f59e0b; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Important Note**: The Cholesky ordering is an **identification assumption**, not something we can test from the data. Different orderings can produce different IRF patterns. Economic theory should guide the choice of ordering. For example, if `y1` is a policy variable (like interest rates) and `y2` is a market variable (like stock prices), it's reasonable to assume policy affects markets immediately, but markets affect policy with a lag.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: IRFs are the **workhorse of VAR analysis**. They transform the estimated coefficients into interpretable dynamic responses, making VAR models powerful tools for policy analysis, forecasting, and understanding economic mechanisms. The ability to trace how shocks propagate through the system over multiple periods is what makes VAR models superior to static correlation analysis.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e0e06f",
   "metadata": {},
   "source": [
    "### 1.3 Vector Error Correction Model (VECM)\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate cointegrated variables and demonstrate the Vector Error Correction Model (VECM). VECM combines short-run dynamics with long-run equilibrium relationships, showing how variables adjust when they deviate from their long-run relationship.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Cointegration** occurs when two or more non-stationary (integrated) variables share a **common stochastic trend**, meaning they move together in the long run even though they may diverge in the short run.\n",
    "\n",
    "**Mathematical Framework**:\n",
    "\n",
    "If $\\mathbf{y}_t$ is a vector of $I(1)$ variables (integrated of order 1, i.e., non-stationary but first-differenced series are stationary), and there exists a vector $\\boldsymbol{\\beta}$ such that $\\boldsymbol{\\beta}' \\mathbf{y}_t$ is $I(0)$ (stationary), then $\\mathbf{y}_t$ is **cointegrated** with cointegrating vector $\\boldsymbol{\\beta}$.\n",
    "\n",
    "**VECM Representation**:\n",
    "\n",
    "The **Vector Error Correction Model** for a VAR(p) with cointegration is:\n",
    "\n",
    "$$\\Delta \\mathbf{y}_t = \\boldsymbol{\\alpha} \\boldsymbol{\\beta}' \\mathbf{y}_{t-1} + \\sum_{i=1}^{p-1} \\mathbf{\\Gamma}_i \\Delta \\mathbf{y}_{t-i} + \\mathbf{u}_t$$\n",
    "\n",
    "where:\n",
    "- $\\Delta \\mathbf{y}_t = \\mathbf{y}_t - \\mathbf{y}_{t-1}$ is the first difference\n",
    "- $\\boldsymbol{\\alpha}$ is the **speed of adjustment** vector (how quickly variables adjust to disequilibrium)\n",
    "- $\\boldsymbol{\\beta}$ is the **cointegrating vector** (the long-run relationship)\n",
    "- $\\mathbf{\\Gamma}_i$ are matrices of short-run dynamics\n",
    "- $\\boldsymbol{\\beta}' \\mathbf{y}_{t-1}$ is the **error correction term** (deviation from long-run equilibrium)\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "1. **Error Correction Term**: $\\boldsymbol{\\beta}' \\mathbf{y}_{t-1}$ measures the deviation from the long-run equilibrium. If $\\beta_1 y_{1,t-1} + \\beta_2 y_{2,t-1} = 0$ represents the equilibrium, then $\\boldsymbol{\\beta}' \\mathbf{y}_{t-1}$ measures how far the system is from equilibrium.\n",
    "\n",
    "2. **Speed of Adjustment**: The elements of $\\boldsymbol{\\alpha}$ determine:\n",
    "   - **Sign**: Negative values mean the variable adjusts **toward** equilibrium (error correction)\n",
    "   - **Magnitude**: Larger (in absolute value) means **faster** adjustment\n",
    "   - **Zero**: If $\\alpha_i = 0$, variable $i$ does not adjust (it's weakly exogenous)\n",
    "\n",
    "3. **Short-Run Dynamics**: The $\\mathbf{\\Gamma}_i$ terms capture short-run fluctuations that are independent of the long-run relationship.\n",
    "\n",
    "**Bivariate Example**:\n",
    "\n",
    "For two variables $(y_{1t}, y_{2t})$ with cointegrating vector $\\boldsymbol{\\beta} = (1, -\\beta_2)'$, the long-run relationship is:\n",
    "\n",
    "$$y_{1t} = \\beta_2 y_{2t} + \\text{stationary error}$$\n",
    "\n",
    "The VECM becomes:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\Delta y_{1t} &= \\alpha_1 (y_{1,t-1} - \\beta_2 y_{2,t-1}) + \\gamma_{11} \\Delta y_{1,t-1} + \\gamma_{12} \\Delta y_{2,t-1} + u_{1t} \\\\\n",
    "\\Delta y_{2t} &= \\alpha_2 (y_{1,t-1} - \\beta_2 y_{2,t-1}) + \\gamma_{21} \\Delta y_{1,t-1} + \\gamma_{22} \\Delta y_{2,t-1} + u_{2t}\n",
    "\\end{aligned}$$\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: VECM models are essential when variables are **cointegrated** because:\n",
    "- They avoid the **spurious regression** problem (regressing non-stationary variables on each other)\n",
    "- They separate **long-run relationships** (cointegration) from **short-run dynamics** (error correction)\n",
    "- They allow variables to **diverge temporarily** but **converge in the long run**\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45570c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "* ============================================================================\n",
    "* Simulation 3: Vector Error Correction Model (VECM)\n",
    "* ============================================================================\n",
    "* Simulate cointegrated bivariate series and demonstrate error correction\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Method: Generate cointegrated series using common trend\n",
    "* Cointegrating relationship: y1_t = beta * y2_t + e_t, where e_t is stationary\n",
    "* We'll generate y2 as a random walk, then y1 as beta*y2 plus a stationary error\n",
    "\n",
    "* Set cointegration parameters\n",
    "scalar beta = 1.5  // Cointegrating coefficient: y1 = 1.5 * y2 + error\n",
    "scalar alpha1 = -0.3  // Speed of adjustment for y1 (negative = error correction)\n",
    "scalar alpha2 = 0.1  // Speed of adjustment for y2 (positive = error increasing)\n",
    "\n",
    "* Generate common stochastic trend (random walk)\n",
    "generate trend = .  // Initialize trend\n",
    "replace trend = 0 if t == 1  // Initial condition\n",
    "generate u_trend = rnormal(0, 1)  // Innovation to trend\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        replace trend = L.trend + u_trend if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate stationary error term (AR(1) process)\n",
    "generate e = .  // Initialize error term\n",
    "replace e = 0 if t == 1  // Initial condition\n",
    "generate u_e = rnormal(0, 0.5)  // Innovation to error (smaller variance)\n",
    "scalar rho_e = 0.7  // AR(1) coefficient for error term\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        replace e = rho_e * L.e + u_e if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate cointegrated series\n",
    "* y2_t = trend_t (random walk, I(1))\n",
    "* y1_t = beta * y2_t + e_t (cointegrated with y2)\n",
    "generate y2 = trend  // y2 is the common trend\n",
    "generate y1 = beta * y2 + e  // y1 = beta * y2 + stationary error\n",
    "\n",
    "* Verify cointegration: y1 - beta*y2 should be stationary\n",
    "generate ecm = y1 - beta * y2  // Error correction term (should be stationary)\n",
    "\n",
    "* Test for unit root in levels and differences\n",
    "* (In practice, use ADF test, but for simulation we can check visually)\n",
    "dfuller y1, lags(4)  // Augmented Dickey-Fuller test for y1\n",
    "dfuller y2, lags(4)  // Augmented Dickey-Fuller test for y2\n",
    "dfuller ecm, lags(4)  // ADF test for error correction term (should reject unit root)\n",
    "\n",
    "* Generate first differences\n",
    "generate dy1 = D.y1  // First difference of y1\n",
    "generate dy2 = D.y2  // First difference of y2\n",
    "\n",
    "* Estimate VECM\n",
    "* VECM: Delta y_t = alpha * beta' * y_{t-1} + Gamma * Delta y_{t-1} + u_t\n",
    "* In Stata, we use vecrank to determine cointegration rank, then vec to estimate VECM\n",
    "\n",
    "* Test for cointegration rank (Johansen test)\n",
    "vecrank y1 y2, trend(constant) lags(2)  // Test cointegration rank\n",
    "\n",
    "* Estimate VECM (assuming rank 1, which we know from construction)\n",
    "vec y1 y2, rank(1) lags(2)  // Estimate VECM with 1 cointegrating vector and 2 lags\n",
    "\n",
    "* Display VECM results\n",
    "display \"\"\n",
    "display \"VECM Estimation Results:\"\n",
    "display \"Cointegrating vector beta (normalized on y1):\"\n",
    "display \"y1 = \" %6.4f _b[_ce1] \" * y2\"\n",
    "display \"\"\n",
    "display \"Speed of adjustment alpha:\"\n",
    "display \"alpha_1 (y1 equation) = \" %6.4f _b[D_y1:_ce1]\n",
    "display \"alpha_2 (y2 equation) = \" %6.4f _b[D_y2:_ce1]\n",
    "\n",
    "* Plot cointegrated series\n",
    "twoway (line y1 t) (line y2 t), ///\n",
    "    title(\"Cointegrated Series: y1 and y2\") ///\n",
    "    ytitle(\"Value\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"y1_t\") label(2 \"y2_t\")) ///\n",
    "    name(ts_coint, replace) // Save graph\n",
    "\n",
    "* Plot error correction term (should be stationary)\n",
    "twoway (line ecm t), ///\n",
    "    title(\"Error Correction Term: y1 - beta*y2 (Stationary)\") ///\n",
    "    ytitle(\"ECM\") xtitle(\"Time\") ///\n",
    "    yline(0, lcolor(red) lpattern(dash)) ///\n",
    "    name(ts_ecm, replace) // Save graph\n",
    "\n",
    "* Plot first differences (should be stationary)\n",
    "twoway (line dy1 t) (line dy2 t), ///\n",
    "    title(\"First Differences (Stationary)\") ///\n",
    "    ytitle(\"Delta\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"Delta y1\") label(2 \"Delta y2\")) ///\n",
    "    name(ts_diff, replace) // Save graph\n",
    "\n",
    "* Summary statistics\n",
    "display \"\"\n",
    "display \"Summary Statistics:\"\n",
    "summarize y1 y2 ecm dy1 dy2, detail\n",
    "\n",
    "display \"\"\n",
    "display \"Theoretical cointegrating coefficient beta = \" %6.4f beta\n",
    "display \"Error correction term (y1 - beta*y2) should be stationary\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70fb23a",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Cointegration Verification**: The ADF test on the error correction term `ecm = y1 - beta*y2` should **reject the null of unit root**, confirming that the linear combination is stationary. This is the defining property of cointegration.\n",
    "\n",
    "2. **Long-Run Relationship**: The estimated cointegrating vector should be close to the theoretical value $\\beta = 1.5$. This means that in the long run, `y1` and `y2` maintain a stable relationship: `y1 ‚âà 1.5 * y2`.\n",
    "\n",
    "3. **Error Correction Mechanism**: \n",
    "   - If `alpha_1 < 0`: When `y1` is above its long-run value (positive error correction term), `y1` **decreases** in the next period, moving back toward equilibrium\n",
    "   - If `alpha_2 > 0`: When `y1` is above its long-run value, `y2` **increases**, also moving toward equilibrium\n",
    "   - The **speed of adjustment** (magnitude of $\\alpha$) determines how quickly the system returns to equilibrium\n",
    "\n",
    "4. **Visual Evidence**: \n",
    "   - The time series plot shows both `y1` and `y2` trending together (they share a common stochastic trend)\n",
    "   - The error correction term plot shows **mean reversion**‚Äîdeviations from equilibrium are temporary\n",
    "   - First differences are stationary (no trend), confirming that levels are $I(1)$\n",
    "\n",
    "5. **Short-Run vs. Long-Run**: The VECM separates:\n",
    "   - **Long-run**: The cointegrating relationship `y1 = beta * y2`\n",
    "   - **Short-run**: The error correction and lagged differences capture temporary deviations\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**‚ö†Ô∏è Warning**: If variables are **not cointegrated**, estimating a VECM is inappropriate. You should:\n",
    "1. First test for unit roots in individual series (ADF test)\n",
    "2. If both are $I(1)$, test for cointegration (Johansen test or Engle-Granger)\n",
    "3. Only estimate VECM if cointegration is confirmed\n",
    "4. If no cointegration, use VAR in **first differences** instead\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: VECM models are powerful because they allow us to model **non-stationary variables** while avoiding spurious regression. They capture the economic intuition that some variables may diverge in the short run (due to shocks) but must converge in the long run (due to economic forces like arbitrage, purchasing power parity, or budget constraints).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8838937",
   "metadata": {},
   "source": [
    "### 1.4 Multivariate ARMA\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate a VARMA(1,1) process, which combines Vector Autoregression (VAR) and Vector Moving Average (VMA) components. This extends the univariate ARMA model to multiple variables, allowing for richer dynamics.\n",
    "\n",
    "</div>\n",
    "\n",
    "The **Vector ARMA of order (1,1)** or **VARMA(1,1)** is defined as:\n",
    "\n",
    "$$\\mathbf{y}_t = \\mathbf{c} + \\mathbf{\\Phi}_1 \\mathbf{y}_{t-1} + \\mathbf{u}_t + \\mathbf{\\Theta}_1 \\mathbf{u}_{t-1}$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{y}_t$ is a $n \\times 1$ vector of variables\n",
    "- $\\mathbf{c}$ is a $n \\times 1$ vector of intercepts\n",
    "- $\\mathbf{\\Phi}_1$ is a $n \\times n$ AR coefficient matrix\n",
    "- $\\mathbf{\\Theta}_1$ is a $n \\times n$ MA coefficient matrix\n",
    "- $\\mathbf{u}_t$ is a $n \\times 1$ vector of innovations\n",
    "\n",
    "**Key Properties**:\n",
    "\n",
    "1. **Combines VAR and VMA**: VARMA models capture both:\n",
    "   - **Persistence** from the AR component (how past values affect current values)\n",
    "   - **Shock absorption** from the MA component (how past shocks affect current values)\n",
    "\n",
    "2. **Parsimony**: VARMA models can often capture the same dynamics as higher-order VAR or VMA models with fewer parameters, making them more efficient.\n",
    "\n",
    "3. **Stationarity and Invertibility**: \n",
    "   - **Stationarity**: Requires all eigenvalues of $\\mathbf{\\Phi}_1$ to lie inside the unit circle\n",
    "   - **Invertibility**: Requires all eigenvalues of $\\mathbf{\\Theta}_1$ to lie inside the unit circle\n",
    "\n",
    "4. **Wold Representation**: Under stationarity and invertibility, VARMA has a unique moving average representation.\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: VARMA models extend the flexibility of univariate ARMA to multivariate settings. They are particularly useful when you need to model both cross-variable dependencies (VAR) and shock dynamics (VMA) simultaneously, while keeping the model parsimonious.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3132e13d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of observations (_N) was 0, now 1,000.\n",
      "\n",
      "\n",
      "\n",
      "Time variable: t, 1 to 1000\n",
      "        Delta: 1 unit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(1 missing value generated)\n",
      "\n",
      "(1 missing value generated)\n",
      "\n",
      "\n",
      ". list t y1 y2 u1 u2 in 1/10\n",
      "\n",
      "     +---------------------------------------------------+\n",
      "     |  t         y1          y2          u1          u2 |\n",
      "     |---------------------------------------------------|\n",
      "  1. |  1          0           0       .9592      1.1458 |\n",
      "  2. |  2   .0395949   -.1938494    -.001805    .0185505 |\n",
      "  3. |  3          .           .     .544077    .7964623 |\n",
      "  4. |  4          .           .    .0016287    .1786604 |\n",
      "  5. |  5          .           .    .3576809    1.088771 |\n",
      "     |---------------------------------------------------|\n",
      "  6. |  6          .           .    1.878868    .1736208 |\n",
      "  7. |  7          .           .    2.754746    2.329023 |\n",
      "  8. |  8          .           .   -.6125968   -1.696012 |\n",
      "  9. |  9          .           .    .1973079    .4954832 |\n",
      " 10. | 10          .           .    1.610224    2.185197 |\n",
      "     +---------------------------------------------------+\n",
      "\n",
      ". display \"Summary Statistics for VARMA(1,1) Process:\"\n",
      "Summary Statistics for VARMA(1,1) Process:\n",
      "\n",
      ". summarize y1 y2 u1 u2, detail\n",
      "\n",
      "                             y1\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%            0              0\n",
      " 5%            0       .0395949\n",
      "10%            0              .       Obs                   2\n",
      "25%            0              .       Sum of wgt.           2\n",
      "\n",
      "50%     .0197975                      Mean           .0197975\n",
      "                        Largest       Std. dev.      .0279978\n",
      "75%     .0395949              .\n",
      "90%     .0395949              .       Variance       .0007839\n",
      "95%     .0395949              0       Skewness              0\n",
      "99%     .0395949       .0395949       Kurtosis              1\n",
      "\n",
      "                             y2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -.1938494      -.1938494\n",
      " 5%    -.1938494              0\n",
      "10%    -.1938494              .       Obs                   2\n",
      "25%    -.1938494              .       Sum of wgt.           2\n",
      "\n",
      "50%    -.0969247                      Mean          -.0969247\n",
      "                        Largest       Std. dev.      .1370722\n",
      "75%            0              .\n",
      "90%            0              .       Variance       .0187888\n",
      "95%            0      -.1938494       Skewness              0\n",
      "99%            0              0       Kurtosis              1\n",
      "\n",
      "                             u1\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -2.421662      -3.355197\n",
      " 5%    -1.644919      -2.949293\n",
      "10%    -1.277207      -2.856949       Obs               1,000\n",
      "25%    -.6367267      -2.809036       Sum of wgt.       1,000\n",
      "\n",
      "50%     .0143557                      Mean           .0141333\n",
      "                        Largest       Std. dev.      1.020651\n",
      "75%     .7212854       2.812786\n",
      "90%     1.347114       2.863938       Variance       1.041728\n",
      "95%     1.626225       3.021777       Skewness      -.0410158\n",
      "99%     2.390601       3.653764       Kurtosis       3.140141\n",
      "\n",
      "                             u2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -2.156776      -3.292919\n",
      " 5%    -1.546628      -2.897869\n",
      "10%    -1.254442      -2.704537       Obs               1,000\n",
      "25%    -.6240222      -2.686282       Sum of wgt.       1,000\n",
      "\n",
      "50%     .0512316                      Mean           .0577229\n",
      "                        Largest       Std. dev.      .9991913\n",
      "75%     .7149692       2.538225\n",
      "90%     1.387875        2.66222       Variance       .9983832\n",
      "95%     1.704172       2.699769       Skewness       .0143169\n",
      "99%     2.348437       3.356136       Kurtosis       2.858177\n",
      "\n",
      ". cap noi twoway (line y1 t) (line y2 t),     title(\"VARMA(1,1): Both Variables\"\n",
      "> )     ytitle(\"Value\") xtitle(\"Time\")     legend(label(1 \"y1_t\") label(2 \"y2_t\"\n",
      "> ))     name(ts_varma, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph3.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph3.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi ac y1, lags(20) name(acf_varma_y1, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi ac y2, lags(20) name(acf_varma_y2, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi xcorr y1 y2, lags(20) name(ccf_varma, replace)\n",
      "lags() too large.  Must be less than -1\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"VARMA(1,1) Parameters:\"\n",
      "VARMA(1,1) Parameters:\n",
      "\n",
      ". display \"Phi_1 = [\" %6.4f phi11 \", \" %6.4f phi12 \"; \" %6.4f phi21 \", \" %6.4f p\n",
      "> hi22 \"]\"\n",
      "Phi_1 = [0.5000, 0.2000; 0.1000, 0.6000]\n",
      "\n",
      ". display \"Theta_1 = [\" %6.4f theta11 \", \" %6.4f theta12 \"; \" %6.4f theta21 \", \"\n",
      ">  %6.4f theta22 \"]\"\n",
      "Theta_1 = [-0.3000, 0.2000; 0.1000, -0.4000]\n",
      "\n",
      ". display \"Innovation correlation = \" %6.4f rho\n",
      "Innovation correlation = 0.3000\n"
     ]
    }
   ],
   "source": [
    "* ============================================================================\n",
    "* Simulation 4: Multivariate ARMA (VARMA(1,1))\n",
    "* ============================================================================\n",
    "* Simulate VARMA(1,1): y_t = c + Phi_1 * y_{t-1} + u_t + Theta_1 * u_{t-1}\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set VARMA(1,1) parameters\n",
    "* AR coefficient matrix Phi_1:\n",
    "*   [phi_11  phi_12]   [0.5   0.2]\n",
    "*   [phi_21  phi_22] = [0.1   0.6]\n",
    "scalar phi11 = 0.5  // AR coefficient: y1_{t-1} -> y1_t\n",
    "scalar phi12 = 0.2  // AR coefficient: y2_{t-1} -> y1_t\n",
    "scalar phi21 = 0.1  // AR coefficient: y1_{t-1} -> y2_t\n",
    "scalar phi22 = 0.6  // AR coefficient: y2_{t-1} -> y2_t\n",
    "\n",
    "* MA coefficient matrix Theta_1:\n",
    "*   [theta_11  theta_12]   [-0.3   0.2]\n",
    "*   [theta_21  theta_22] = [0.1   -0.4]\n",
    "scalar theta11 = -0.3  // MA coefficient: u1_{t-1} -> y1_t\n",
    "scalar theta12 = 0.2   // MA coefficient: u2_{t-1} -> y1_t\n",
    "scalar theta21 = 0.1   // MA coefficient: u1_{t-1} -> y2_t\n",
    "scalar theta22 = -0.4  // MA coefficient: u2_{t-1} -> y2_t\n",
    "\n",
    "* Intercept vector\n",
    "scalar c1 = 0.1  // Intercept for equation 1\n",
    "scalar c2 = 0.15  // Intercept for equation 2\n",
    "\n",
    "* Innovation covariance matrix (same as VAR example)\n",
    "scalar sigma1 = 1.0  // Standard deviation of u1_t\n",
    "scalar sigma2 = 1.0  // Standard deviation of u2_t\n",
    "scalar sigma12 = 0.3  // Covariance between u1_t and u2_t\n",
    "\n",
    "* Generate correlated innovations using Cholesky decomposition\n",
    "scalar rho = sigma12 / (sigma1 * sigma2)  // Correlation\n",
    "scalar L11 = sigma1\n",
    "scalar L21 = sigma12 / sigma1\n",
    "scalar L22 = sqrt(sigma2^2 - (sigma12/sigma1)^2)\n",
    "\n",
    "generate z1 = rnormal()  // Independent standard normal\n",
    "generate z2 = rnormal()  // Independent standard normal\n",
    "generate u1 = L11 * z1  // Correlated innovation 1\n",
    "generate u2 = L21 * z1 + L22 * z2  // Correlated innovation 2\n",
    "\n",
    "* Initialize VARMA(1,1) variables\n",
    "generate y1 = .  // Initialize y1\n",
    "generate y2 = .  // Initialize y2\n",
    "\n",
    "* Set initial conditions\n",
    "replace y1 = 0 if t == 1  // Initial condition y1_1 = 0\n",
    "replace y2 = 0 if t == 1  // Initial condition y2_1 = 0\n",
    "\n",
    "* Generate lagged variables and innovations\n",
    "generate y1_lag1 = L.y1  // Lag-1 of y1\n",
    "generate y2_lag1 = L.y2  // Lag-1 of y2\n",
    "generate u1_lag1 = L.u1  // Lag-1 of u1\n",
    "generate u2_lag1 = L.u2  // Lag-1 of u2\n",
    "\n",
    "* Recursively generate VARMA(1,1) process:\n",
    "* y1_t = c1 + phi11*y1_{t-1} + phi12*y2_{t-1} + u1_t + theta11*u1_{t-1} + theta12*u2_{t-1}\n",
    "* y2_t = c2 + phi21*y1_{t-1} + phi22*y2_{t-1} + u2_t + theta21*u1_{t-1} + theta22*u2_{t-1}\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        replace y1 = c1 + phi11*y1_lag1 + phi12*y2_lag1 + u1 + theta11*u1_lag1 + theta12*u2_lag1 if t == `i'\n",
    "        replace y2 = c2 + phi21*y1_lag1 + phi22*y2_lag1 + u2 + theta21*u1_lag1 + theta22*u2_lag1 if t == `i'\n",
    "        * Update lagged variables\n",
    "        replace y1_lag1 = L.y1 if t == `i'\n",
    "        replace y2_lag1 = L.y2 if t == `i'\n",
    "        replace u1_lag1 = L.u1 if t == `i'\n",
    "        replace u2_lag1 = L.u2 if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Display first 10 observations\n",
    "list t y1 y2 u1 u2 in 1/10\n",
    "\n",
    "* Summary statistics\n",
    "display \"Summary Statistics for VARMA(1,1) Process:\"\n",
    "summarize y1 y2 u1 u2, detail\n",
    "\n",
    "* Time series plots\n",
    "twoway (line y1 t) (line y2 t), ///\n",
    "    title(\"VARMA(1,1): Both Variables\") ///\n",
    "    ytitle(\"Value\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"y1_t\") label(2 \"y2_t\")) ///\n",
    "    name(ts_varma, replace)\n",
    "\n",
    "* Autocorrelation functions\n",
    "ac y1, lags(20) name(acf_varma_y1, replace)\n",
    "ac y2, lags(20) name(acf_varma_y2, replace)\n",
    "\n",
    "* Cross-correlation function\n",
    "xcorr y1 y2, lags(20) name(ccf_varma, replace)\n",
    "\n",
    "display \"\"\n",
    "display \"VARMA(1,1) Parameters:\"\n",
    "display \"Phi_1 = [\" %6.4f phi11 \", \" %6.4f phi12 \"; \" %6.4f phi21 \", \" %6.4f phi22 \"]\"\n",
    "display \"Theta_1 = [\" %6.4f theta11 \", \" %6.4f theta12 \"; \" %6.4f theta21 \", \" %6.4f theta22 \"]\"\n",
    "display \"Innovation correlation = \" %6.4f rho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6960c",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Combined Dynamics**: VARMA(1,1) combines the persistence of VAR with the shock-absorption properties of VMA. The ACF shows a more complex pattern than pure VAR or pure VMA, with both exponential decay (from AR) and cut-off patterns (from MA).\n",
    "\n",
    "2. **Cross-Variable Effects**: Both AR and MA components operate across variables:\n",
    "   - AR effects: Past values of both variables affect current values\n",
    "   - MA effects: Past shocks to both variables affect current values\n",
    "\n",
    "3. **Parsimony**: VARMA(1,1) can capture dynamics that would require higher-order VAR or VMA models, making it more efficient in parameter usage.\n",
    "\n",
    "4. **Comparison with Univariate ARMA**: The multivariate extension allows for:\n",
    "   - **Cross-variable AR effects**: How one variable's past affects another\n",
    "   - **Cross-variable MA effects**: How one variable's past shocks affect another\n",
    "   - **Correlated innovations**: Contemporaneous correlation between error terms\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: VARMA models provide a flexible framework for modeling multivariate time series with both persistence and shock dynamics. They are particularly useful when you need to capture complex interdependencies while maintaining model parsimony.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541ef079",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"../notebook_styles.css\">\n",
    "\n",
    "<a id=\"section-2\"></a>\n",
    "<h2 class=\"styled-header\">2) Volatility Modeling</h2>\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç Conceptual Foundation**: **Volatility modeling** addresses a fundamental feature of financial and economic time series: **time-varying variance**. Unlike standard time series models that assume constant variance (homoskedasticity), volatility models allow the variance to change over time, capturing phenomena like **volatility clustering**‚Äîperiods of high volatility followed by high volatility, and periods of low volatility followed by low volatility.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Why Volatility Matters**:\n",
    "\n",
    "1. **Risk Management**: Volatility is a key measure of risk. Accurate volatility forecasts are essential for:\n",
    "   - Portfolio optimization\n",
    "   - Value-at-Risk (VaR) calculations\n",
    "   - Option pricing (Black-Scholes requires volatility estimates)\n",
    "\n",
    "2. **Financial Stylized Facts**: Financial returns exhibit:\n",
    "   - **Volatility clustering**: Large price changes tend to be followed by large changes\n",
    "   - **Fat tails**: Extreme events occur more frequently than normal distribution predicts\n",
    "   - **Leverage effects**: Negative returns increase volatility more than positive returns\n",
    "\n",
    "3. **Economic Policy**: Understanding volatility dynamics helps policymakers:\n",
    "   - Assess uncertainty in economic forecasts\n",
    "   - Design policies that account for volatility regimes\n",
    "   - Understand transmission of volatility across markets\n",
    "\n",
    "**Key Volatility Models**:\n",
    "\n",
    "1. **ARCH (Autoregressive Conditional Heteroskedasticity)**: Models volatility as a function of past squared innovations\n",
    "2. **GARCH (Generalized ARCH)**: Extends ARCH by including lagged volatility terms\n",
    "3. **Multivariate GARCH**: Models time-varying correlations between multiple assets\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Why This Matters**: Volatility models are essential for understanding and forecasting risk. They transform our understanding from \"returns are unpredictable\" to \"returns are unpredictable, but their volatility is predictable.\" This predictability of volatility is what makes risk management and option pricing possible.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a394a1",
   "metadata": {},
   "source": [
    "### 2.1 ARCH Models\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate an ARCH(1) process to demonstrate volatility clustering. We'll show how large shocks lead to periods of high volatility, which then gradually decay, creating the characteristic clustering pattern observed in financial returns.\n",
    "\n",
    "</div>\n",
    "\n",
    "The **ARCH(1) model** is defined as:\n",
    "\n",
    "$$r_t = \\mu + \\varepsilon_t$$\n",
    "\n",
    "where the innovation $\\varepsilon_t$ has time-varying variance:\n",
    "\n",
    "$$\\varepsilon_t = \\sigma_t z_t, \\quad z_t \\sim N(0,1)$$\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\alpha_1 \\varepsilon_{t-1}^2$$\n",
    "\n",
    "where:\n",
    "- $r_t$ is the return (or mean-adjusted return)\n",
    "- $\\mu$ is the mean return (often set to zero)\n",
    "- $\\sigma_t^2$ is the **conditional variance** (variance at time $t$ given information at $t-1$)\n",
    "- $\\omega > 0$ is the intercept (unconditional variance component)\n",
    "- $\\alpha_1 \\geq 0$ is the ARCH coefficient\n",
    "- $z_t$ is standard normal white noise\n",
    "\n",
    "**Key Properties**:\n",
    "\n",
    "1. **Conditional vs. Unconditional Variance**:\n",
    "   - **Conditional variance**: $\\sigma_t^2 = \\mathbb{V}(r_t | \\mathcal{F}_{t-1})$ depends on past information\n",
    "   - **Unconditional variance**: $\\sigma^2 = \\mathbb{V}(r_t) = \\frac{\\omega}{1-\\alpha_1}$ (if $\\alpha_1 < 1$)\n",
    "\n",
    "2. **Stationarity Condition**: For ARCH(1) to be stationary, we need $\\alpha_1 < 1$. If $\\alpha_1 \\geq 1$, the unconditional variance is infinite (non-stationary).\n",
    "\n",
    "3. **Volatility Clustering**: When $\\alpha_1 > 0$:\n",
    "   - A large shock ($\\varepsilon_{t-1}^2$ large) increases $\\sigma_t^2$\n",
    "   - High volatility persists (though decays if $\\alpha_1 < 1$)\n",
    "   - This creates **clustering**: periods of high volatility followed by high volatility\n",
    "\n",
    "4. **Fat Tails**: ARCH processes generate **leptokurtic** (fat-tailed) distributions, even when $z_t$ is normal, because the mixing of normal distributions with time-varying variance creates excess kurtosis.\n",
    "\n",
    "**Mathematical Derivation of Unconditional Variance**:\n",
    "\n",
    "Under stationarity, the unconditional variance is constant: $\\mathbb{E}[\\sigma_t^2] = \\sigma^2$.\n",
    "\n",
    "Taking expectations of the ARCH equation:\n",
    "\n",
    "$$\\mathbb{E}[\\sigma_t^2] = \\omega + \\alpha_1 \\mathbb{E}[\\varepsilon_{t-1}^2]$$\n",
    "\n",
    "Since $\\varepsilon_{t-1}^2 = \\sigma_{t-1}^2 z_{t-1}^2$ and $z_{t-1}$ is independent of $\\sigma_{t-1}^2$:\n",
    "\n",
    "$$\\mathbb{E}[\\varepsilon_{t-1}^2] = \\mathbb{E}[\\sigma_{t-1}^2] \\mathbb{E}[z_{t-1}^2] = \\sigma^2 \\cdot 1 = \\sigma^2$$\n",
    "\n",
    "Substituting:\n",
    "\n",
    "$$\\sigma^2 = \\omega + \\alpha_1 \\sigma^2$$\n",
    "\n",
    "Solving for $\\sigma^2$:\n",
    "\n",
    "$$\\sigma^2(1 - \\alpha_1) = \\omega \\quad \\Rightarrow \\quad \\sigma^2 = \\frac{\\omega}{1-\\alpha_1}$$\n",
    "\n",
    "This requires $\\alpha_1 < 1$ for a finite unconditional variance.\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: ARCH models capture **volatility clustering** by making current volatility depend on past squared innovations. This simple mechanism explains a wide range of financial phenomena, from the clustering of large price movements to the fat-tailed distribution of returns.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0696eba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of observations (_N) was 0, now 1,000.\n",
      "\n",
      "\n",
      "\n",
      "Time variable: t, 1 to 1000\n",
      "        Delta: 1 unit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "ARCH(1) Parameters:\n",
      "\n",
      "omega = 0.1000\n",
      "\n",
      "alpha_1 = 0.7000\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unconditional variance = 0.3333\n",
      "\n",
      "Unconditional std dev = 0.5774\n",
      "\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "\n",
      ". generate sigma = sqrt(sigma2)  \n",
      "(998 missing values generated)\n",
      "\n",
      ". list t r epsilon sigma2 sigma in 1/10\n",
      "\n",
      "     +--------------------------------------------------+\n",
      "     |  t           r     epsilon     sigma2      sigma |\n",
      "     |--------------------------------------------------|\n",
      "  1. |  1    .5537944    .5537944   .3333333   .5773503 |\n",
      "  2. |  2   -.0010126   -.0010126   .3146818   .5609651 |\n",
      "  3. |  3           .           .          .          . |\n",
      "  4. |  4           .           .          .          . |\n",
      "  5. |  5           .           .          .          . |\n",
      "     |--------------------------------------------------|\n",
      "  6. |  6           .           .          .          . |\n",
      "  7. |  7           .           .          .          . |\n",
      "  8. |  8           .           .          .          . |\n",
      "  9. |  9           .           .          .          . |\n",
      " 10. | 10           .           .          .          . |\n",
      "     +--------------------------------------------------+\n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"Summary Statistics for ARCH(1) Process:\"\n",
      "Summary Statistics for ARCH(1) Process:\n",
      "\n",
      ". summarize r epsilon sigma2 sigma, detail\n",
      "\n",
      "                              r\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -.0010126      -.0010126\n",
      " 5%    -.0010126       .5537944\n",
      "10%    -.0010126              .       Obs                   2\n",
      "25%    -.0010126              .       Sum of wgt.           2\n",
      "\n",
      "50%     .2763909                      Mean           .2763909\n",
      "                        Largest       Std. dev.      .3923078\n",
      "75%     .5537944              .\n",
      "90%     .5537944              .       Variance       .1539054\n",
      "95%     .5537944      -.0010126       Skewness              0\n",
      "99%     .5537944       .5537944       Kurtosis              1\n",
      "\n",
      "                           epsilon\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -.0010126      -.0010126\n",
      " 5%    -.0010126       .5537944\n",
      "10%    -.0010126              .       Obs                   2\n",
      "25%    -.0010126              .       Sum of wgt.           2\n",
      "\n",
      "50%     .2763909                      Mean           .2763909\n",
      "                        Largest       Std. dev.      .3923078\n",
      "75%     .5537944              .\n",
      "90%     .5537944              .       Variance       .1539054\n",
      "95%     .5537944      -.0010126       Skewness              0\n",
      "99%     .5537944       .5537944       Kurtosis              1\n",
      "\n",
      "                           sigma2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .3146818       .3146818\n",
      " 5%     .3146818       .3333333\n",
      "10%     .3146818              .       Obs                   2\n",
      "25%     .3146818              .       Sum of wgt.           2\n",
      "\n",
      "50%     .3240076                      Mean           .3240076\n",
      "                        Largest       Std. dev.      .0131887\n",
      "75%     .3333333              .\n",
      "90%     .3333333              .       Variance       .0001739\n",
      "95%     .3333333       .3146818       Skewness              0\n",
      "99%     .3333333       .3333333       Kurtosis              1\n",
      "\n",
      "                            sigma\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .5609651       .5609651\n",
      " 5%     .5609651       .5773503\n",
      "10%     .5609651              .       Obs                   2\n",
      "25%     .5609651              .       Sum of wgt.           2\n",
      "\n",
      "50%     .5691577                      Mean           .5691577\n",
      "                        Largest       Std. dev.      .0115861\n",
      "75%     .5773503              .\n",
      "90%     .5773503              .       Variance       .0001342\n",
      "95%     .5773503       .5609651       Skewness              0\n",
      "99%     .5773503       .5773503       Kurtosis              1\n",
      "\n",
      ". cap noi twoway (line r t),     title(\"ARCH(1): Returns r_t\")     ytitle(\"r_t\")\n",
      ">  xtitle(\"Time\")     name(ts_arch_ret, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph4.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph4.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line sigma t),     title(\"ARCH(1): Conditional Volatility sigm\n",
      "> a_t\")     ytitle(\"sigma_t\") xtitle(\"Time\")     name(ts_arch_vol, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph5.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph5.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line r t, yaxis(1)) (line sigma t, yaxis(2)),     title(\"ARCH(\n",
      "> 1): Returns and Volatility\")     ytitle(\"Returns\", axis(1)) ytitle(\"Volatility\n",
      "> \", axis(2))     xtitle(\"Time\")     legend(label(1 \"r_t\") label(2 \"sigma_t\"))  \n",
      ">    name(ts_arch_both, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph6.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph6.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi ac r, lags(20) name(acf_arch_ret, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". generate r2 = r^2  \n",
      "(998 missing values generated)\n",
      "\n",
      ". cap noi ac r2, lags(20) name(acf_arch_r2, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi histogram r,     title(\"ARCH(1): Distribution of Returns\")     xtitle(\n",
      "> \"r_t\") ytitle(\"Density\")     normal \n",
      "(bin=1, start=-.00101256, width=.55480694)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph7.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph7.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ".     name(hist_arch, replace)\n",
      "command name is unrecognized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r(199);\n",
      "r(199);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "* ============================================================================\n",
    "* Simulation 5: ARCH(1) Model\n",
    "* ============================================================================\n",
    "* Simulate ARCH(1): r_t = mu + epsilon_t, epsilon_t = sigma_t * z_t\n",
    "* where sigma_t^2 = omega + alpha_1 * epsilon_{t-1}^2\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set ARCH(1) parameters\n",
    "scalar mu = 0.0  // Mean return (often zero for financial returns)\n",
    "scalar omega = 0.1  // Intercept in variance equation (omega > 0)\n",
    "scalar alpha1 = 0.7  // ARCH coefficient (must be < 1 for stationarity)\n",
    "\n",
    "* Verify stationarity: alpha1 < 1\n",
    "display \"ARCH(1) Parameters:\"\n",
    "display \"omega = \" %6.4f omega\n",
    "display \"alpha_1 = \" %6.4f alpha1\n",
    "if alpha1 >= 1 {\n",
    "    display \"WARNING: alpha_1 >= 1, process is non-stationary!\"\n",
    "}\n",
    "\n",
    "* Unconditional variance: sigma^2 = omega / (1 - alpha1)\n",
    "scalar sigma2_uncond = omega / (1 - alpha1)  // Unconditional variance\n",
    "scalar sigma_uncond = sqrt(sigma2_uncond)  // Unconditional standard deviation\n",
    "display \"Unconditional variance = \" %6.4f sigma2_uncond\n",
    "display \"Unconditional std dev = \" %6.4f sigma_uncond\n",
    "\n",
    "* Generate standard normal white noise\n",
    "generate z = rnormal()  // z_t ~ N(0,1)\n",
    "\n",
    "* Initialize ARCH(1) process\n",
    "generate epsilon = .  // Initialize innovation\n",
    "generate sigma2 = .  // Initialize conditional variance\n",
    "generate r = .  // Initialize return\n",
    "\n",
    "* Set initial conditions\n",
    "* Start with unconditional variance\n",
    "replace sigma2 = sigma2_uncond if t == 1  // Initial variance = unconditional variance\n",
    "replace epsilon = sqrt(sigma2) * z if t == 1  // Initial innovation\n",
    "replace r = mu + epsilon if t == 1  // Initial return\n",
    "\n",
    "* Generate lagged squared innovation\n",
    "generate eps2_lag1 = L.epsilon^2  // Lag-1 of squared innovation\n",
    "\n",
    "* Recursively generate ARCH(1) process\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        * Conditional variance: sigma_t^2 = omega + alpha1 * epsilon_{t-1}^2\n",
    "        replace sigma2 = omega + alpha1 * eps2_lag1 if t == `i'\n",
    "        * Innovation: epsilon_t = sigma_t * z_t\n",
    "        replace epsilon = sqrt(sigma2) * z if t == `i'\n",
    "        * Return: r_t = mu + epsilon_t\n",
    "        replace r = mu + epsilon if t == `i'\n",
    "        * Update lagged squared innovation\n",
    "        replace eps2_lag1 = L.epsilon^2 if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate conditional standard deviation\n",
    "generate sigma = sqrt(sigma2)  // Conditional standard deviation\n",
    "\n",
    "* Display first 10 observations\n",
    "list t r epsilon sigma2 sigma in 1/10\n",
    "\n",
    "* Summary statistics\n",
    "display \"\"\n",
    "display \"Summary Statistics for ARCH(1) Process:\"\n",
    "summarize r epsilon sigma2 sigma, detail\n",
    "\n",
    "* Time series plots\n",
    "twoway (line r t), ///\n",
    "    title(\"ARCH(1): Returns r_t\") ///\n",
    "    ytitle(\"r_t\") xtitle(\"Time\") ///\n",
    "    name(ts_arch_ret, replace)\n",
    "\n",
    "twoway (line sigma t), ///\n",
    "    title(\"ARCH(1): Conditional Volatility sigma_t\") ///\n",
    "    ytitle(\"sigma_t\") xtitle(\"Time\") ///\n",
    "    name(ts_arch_vol, replace)\n",
    "\n",
    "* Overlay returns and volatility\n",
    "twoway (line r t, yaxis(1)) (line sigma t, yaxis(2)), ///\n",
    "    title(\"ARCH(1): Returns and Volatility\") ///\n",
    "    ytitle(\"Returns\", axis(1)) ytitle(\"Volatility\", axis(2)) ///\n",
    "    xtitle(\"Time\") ///\n",
    "    legend(label(1 \"r_t\") label(2 \"sigma_t\")) ///\n",
    "    name(ts_arch_both, replace)\n",
    "\n",
    "* Autocorrelation of returns (should be near zero)\n",
    "ac r, lags(20) name(acf_arch_ret, replace)\n",
    "\n",
    "* Autocorrelation of squared returns (should show persistence)\n",
    "generate r2 = r^2  // Squared returns\n",
    "ac r2, lags(20) name(acf_arch_r2, replace)\n",
    "\n",
    "* Histogram of returns (should show fat tails)\n",
    "histogram r, ///\n",
    "    title(\"ARCH(1): Distribution of Returns\") ///\n",
    "    xtitle(\"r_t\") ytitle(\"Density\") ///\n",
    "    normal // Overlay normal distribution ///\n",
    "    name(hist_arch, replace)\n",
    "\n",
    "display \"\"\n",
    "display \"ARCH(1) shows volatility clustering:\"\n",
    "display \"Large |r_t| leads to high sigma_{t+1}, creating clusters of high volatility\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac4ac80",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Volatility Clustering**: The conditional volatility plot shows clear **clustering**‚Äîperiods of high volatility (large $\\sigma_t$) are followed by periods of high volatility, and periods of low volatility are followed by low volatility. This matches the stylized fact observed in financial data.\n",
    "\n",
    "2. **Returns vs. Volatility**: The returns plot shows that large absolute returns tend to occur during high-volatility periods. The overlay plot makes this relationship clear: when volatility spikes, returns become more dispersed.\n",
    "\n",
    "3. **Autocorrelation Structure**:\n",
    "   - **Returns** (`r`): ACF should be near zero (returns are unpredictable)\n",
    "   - **Squared returns** (`r¬≤`): ACF shows **positive autocorrelation**, indicating that volatility is predictable. This is the key insight of ARCH models.\n",
    "\n",
    "4. **Fat Tails**: The histogram of returns should show **fat tails** compared to the normal distribution overlay. Even though innovations $z_t$ are normal, the time-varying variance creates excess kurtosis.\n",
    "\n",
    "5. **Unconditional vs. Conditional Variance**:\n",
    "   - **Conditional variance** ($\\sigma_t^2$) varies over time\n",
    "   - **Unconditional variance** ($\\sigma^2 = \\frac{\\omega}{1-\\alpha_1}$) is constant\n",
    "   - The conditional variance fluctuates around the unconditional variance\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: ARCH models successfully capture **volatility clustering**‚Äîone of the most important stylized facts of financial returns. The mechanism is simple: large shocks increase future volatility, which persists (though decays) over time. This predictability of volatility is what makes risk management and option pricing possible.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc04fece",
   "metadata": {},
   "source": [
    "### 2.2 GARCH Models\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate a GARCH(1,1) process to demonstrate how adding lagged volatility terms creates **persistence** in volatility. GARCH models are more parsimonious than high-order ARCH models and better capture the long memory in volatility observed in financial data.\n",
    "\n",
    "</div>\n",
    "\n",
    "The **GARCH(1,1) model** extends ARCH by including lagged volatility:\n",
    "\n",
    "$$\\sigma_t^2 = \\omega + \\alpha_1 \\varepsilon_{t-1}^2 + \\beta_1 \\sigma_{t-1}^2$$\n",
    "\n",
    "where:\n",
    "- $\\omega > 0$ is the intercept\n",
    "- $\\alpha_1 \\geq 0$ is the ARCH coefficient (effect of past squared innovation)\n",
    "- $\\beta_1 \\geq 0$ is the GARCH coefficient (effect of past volatility)\n",
    "- Stationarity requires: $\\alpha_1 + \\beta_1 < 1$\n",
    "\n",
    "**Key Properties**:\n",
    "\n",
    "1. **Persistence**: The term $\\beta_1 \\sigma_{t-1}^2$ creates **persistence** in volatility. High volatility today leads to high volatility tomorrow, even without new large shocks.\n",
    "\n",
    "2. **Unconditional Variance**: \n",
    "   $$\\sigma^2 = \\frac{\\omega}{1 - \\alpha_1 - \\beta_1}$$\n",
    "   Requires $\\alpha_1 + \\beta_1 < 1$ for stationarity.\n",
    "\n",
    "3. **Mean Reversion**: When $\\alpha_1 + \\beta_1 < 1$, volatility is **mean-reverting**‚Äîit tends to return to the long-run average $\\sigma^2$.\n",
    "\n",
    "4. **Long Memory**: GARCH(1,1) can capture long memory in volatility with just three parameters, making it more parsimonious than high-order ARCH models.\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: GARCH models are the **workhorse of volatility modeling** because they capture volatility persistence with few parameters. The GARCH(1,1) model is often sufficient to model financial volatility, making it the most widely used volatility model in practice.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32eb54dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of observations (_N) was 0, now 1,000.\n",
      "\n",
      "\n",
      "\n",
      "Time variable: t, 1 to 1000\n",
      "        Delta: 1 unit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "GARCH(1,1) Parameters:\n",
      "\n",
      "omega = 0.0500\n",
      "\n",
      "alpha_1 = 0.1000\n",
      "\n",
      "beta_1 = 0.8500\n",
      "\n",
      "Persistence (alpha_1 + beta_1) = 0.9500\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Unconditional variance = 1.0000\n",
      "\n",
      "Unconditional std dev = 1.0000\n",
      "\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "\n",
      ". generate sigma = sqrt(sigma2)\n",
      "(998 missing values generated)\n",
      "\n",
      ". list t r epsilon sigma2 sigma in 1/10\n",
      "\n",
      "     +--------------------------------------------------+\n",
      "     |  t           r     epsilon     sigma2      sigma |\n",
      "     |--------------------------------------------------|\n",
      "  1. |  1       .9592       .9592          1          1 |\n",
      "  2. |  2   -.0017978   -.0017978   .9920065   .9959952 |\n",
      "  3. |  3           .           .          .          . |\n",
      "  4. |  4           .           .          .          . |\n",
      "  5. |  5           .           .          .          . |\n",
      "     |--------------------------------------------------|\n",
      "  6. |  6           .           .          .          . |\n",
      "  7. |  7           .           .          .          . |\n",
      "  8. |  8           .           .          .          . |\n",
      "  9. |  9           .           .          .          . |\n",
      " 10. | 10           .           .          .          . |\n",
      "     +--------------------------------------------------+\n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"Summary Statistics for GARCH(1,1) Process:\"\n",
      "Summary Statistics for GARCH(1,1) Process:\n",
      "\n",
      ". summarize r epsilon sigma2 sigma, detail\n",
      "\n",
      "                              r\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -.0017978      -.0017978\n",
      " 5%    -.0017978          .9592\n",
      "10%    -.0017978              .       Obs                   2\n",
      "25%    -.0017978              .       Sum of wgt.           2\n",
      "\n",
      "50%     .4787011                      Mean           .4787011\n",
      "                        Largest       Std. dev.       .679528\n",
      "75%        .9592              .\n",
      "90%        .9592              .       Variance       .4617584\n",
      "95%        .9592      -.0017978       Skewness              0\n",
      "99%        .9592          .9592       Kurtosis              1\n",
      "\n",
      "                           epsilon\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -.0017978      -.0017978\n",
      " 5%    -.0017978          .9592\n",
      "10%    -.0017978              .       Obs                   2\n",
      "25%    -.0017978              .       Sum of wgt.           2\n",
      "\n",
      "50%     .4787011                      Mean           .4787011\n",
      "                        Largest       Std. dev.       .679528\n",
      "75%        .9592              .\n",
      "90%        .9592              .       Variance       .4617584\n",
      "95%        .9592      -.0017978       Skewness              0\n",
      "99%        .9592          .9592       Kurtosis              1\n",
      "\n",
      "                           sigma2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .9920065       .9920065\n",
      " 5%     .9920065              1\n",
      "10%     .9920065              .       Obs                   2\n",
      "25%     .9920065              .       Sum of wgt.           2\n",
      "\n",
      "50%     .9960032                      Mean           .9960032\n",
      "                        Largest       Std. dev.      .0056523\n",
      "75%            1              .\n",
      "90%            1              .       Variance       .0000319\n",
      "95%            1       .9920065       Skewness              0\n",
      "99%            1              1       Kurtosis              1\n",
      "\n",
      "                            sigma\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .9959952       .9959952\n",
      " 5%     .9959952              1\n",
      "10%     .9959952              .       Obs                   2\n",
      "25%     .9959952              .       Sum of wgt.           2\n",
      "\n",
      "50%     .9979976                      Mean           .9979976\n",
      "                        Largest       Std. dev.      .0028318\n",
      "75%            1              .\n",
      "90%            1              .       Variance       8.02e-06\n",
      "95%            1       .9959952       Skewness              0\n",
      "99%            1              1       Kurtosis              1\n",
      "\n",
      ". cap noi twoway (line r t),     title(\"GARCH(1,1): Returns r_t\")     ytitle(\"r_\n",
      "> t\") xtitle(\"Time\")     name(ts_garch_ret, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph8.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph8.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line sigma t),     title(\"GARCH(1,1): Conditional Volatility s\n",
      "> igma_t\")     ytitle(\"sigma_t\") xtitle(\"Time\")     name(ts_garch_vol, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph9.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph9.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line r t, yaxis(1)) (line sigma t, yaxis(2)),     title(\"GARCH\n",
      "> (1,1): Returns and Volatility\")     ytitle(\"Returns\", axis(1)) ytitle(\"Volatil\n",
      "> ity\", axis(2))     xtitle(\"Time\")     legend(label(1 \"r_t\") label(2 \"sigma_t\")\n",
      "> )     name(ts_garch_both, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph10.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph10.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". generate r2 = r^2\n",
      "(998 missing values generated)\n",
      "\n",
      ". cap noi ac r2, lags(20) name(acf_garch_r2, replace)\n",
      "lags() too large; must be less than 2\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"GARCH(1,1) shows stronger persistence than ARCH(1):\"\n",
      "GARCH(1,1) shows stronger persistence than ARCH(1):\n",
      "\n",
      ". display \"Volatility persists through beta_1 * sigma_{t-1}^2 term\"\n",
      "Volatility persists through beta_1 * sigma_{t-1}^2 term\n"
     ]
    }
   ],
   "source": [
    "* ============================================================================\n",
    "* Simulation 6: GARCH(1,1) Model\n",
    "* ============================================================================\n",
    "* Simulate GARCH(1,1): r_t = mu + epsilon_t, epsilon_t = sigma_t * z_t\n",
    "* where sigma_t^2 = omega + alpha_1 * epsilon_{t-1}^2 + beta_1 * sigma_{t-1}^2\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set GARCH(1,1) parameters\n",
    "scalar mu = 0.0  // Mean return\n",
    "scalar omega = 0.05  // Intercept in variance equation\n",
    "scalar alpha1 = 0.1  // ARCH coefficient (effect of past squared innovation)\n",
    "scalar beta1 = 0.85  // GARCH coefficient (effect of past volatility)\n",
    "\n",
    "* Verify stationarity: alpha1 + beta1 < 1\n",
    "scalar persistence = alpha1 + beta1  // Persistence parameter\n",
    "display \"GARCH(1,1) Parameters:\"\n",
    "display \"omega = \" %6.4f omega\n",
    "display \"alpha_1 = \" %6.4f alpha1\n",
    "display \"beta_1 = \" %6.4f beta1\n",
    "display \"Persistence (alpha_1 + beta_1) = \" %6.4f persistence\n",
    "if persistence >= 1 {\n",
    "    display \"WARNING: alpha_1 + beta_1 >= 1, process is non-stationary!\"\n",
    "}\n",
    "\n",
    "* Unconditional variance: sigma^2 = omega / (1 - alpha1 - beta1)\n",
    "scalar sigma2_uncond = omega / (1 - persistence)  // Unconditional variance\n",
    "scalar sigma_uncond = sqrt(sigma2_uncond)  // Unconditional standard deviation\n",
    "display \"Unconditional variance = \" %6.4f sigma2_uncond\n",
    "display \"Unconditional std dev = \" %6.4f sigma_uncond\n",
    "\n",
    "* Generate standard normal white noise\n",
    "generate z = rnormal()  // z_t ~ N(0,1)\n",
    "\n",
    "* Initialize GARCH(1,1) process\n",
    "generate epsilon = .  // Initialize innovation\n",
    "generate sigma2 = .  // Initialize conditional variance\n",
    "generate r = .  // Initialize return\n",
    "\n",
    "* Set initial conditions\n",
    "replace sigma2 = sigma2_uncond if t == 1  // Start at unconditional variance\n",
    "replace epsilon = sqrt(sigma2) * z if t == 1\n",
    "replace r = mu + epsilon if t == 1\n",
    "\n",
    "* Generate lagged terms\n",
    "generate eps2_lag1 = L.epsilon^2  // Lag-1 of squared innovation\n",
    "generate sigma2_lag1 = L.sigma2  // Lag-1 of conditional variance\n",
    "\n",
    "* Recursively generate GARCH(1,1) process\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        * Conditional variance: sigma_t^2 = omega + alpha1*epsilon_{t-1}^2 + beta1*sigma_{t-1}^2\n",
    "        replace sigma2 = omega + alpha1 * eps2_lag1 + beta1 * sigma2_lag1 if t == `i'\n",
    "        * Innovation: epsilon_t = sigma_t * z_t\n",
    "        replace epsilon = sqrt(sigma2) * z if t == `i'\n",
    "        * Return: r_t = mu + epsilon_t\n",
    "        replace r = mu + epsilon if t == `i'\n",
    "        * Update lagged terms\n",
    "        replace eps2_lag1 = L.epsilon^2 if t == `i'\n",
    "        replace sigma2_lag1 = L.sigma2 if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate conditional standard deviation\n",
    "generate sigma = sqrt(sigma2)\n",
    "\n",
    "* Display first 10 observations\n",
    "list t r epsilon sigma2 sigma in 1/10\n",
    "\n",
    "* Summary statistics\n",
    "display \"\"\n",
    "display \"Summary Statistics for GARCH(1,1) Process:\"\n",
    "summarize r epsilon sigma2 sigma, detail\n",
    "\n",
    "* Time series plots\n",
    "twoway (line r t), ///\n",
    "    title(\"GARCH(1,1): Returns r_t\") ///\n",
    "    ytitle(\"r_t\") xtitle(\"Time\") ///\n",
    "    name(ts_garch_ret, replace)\n",
    "\n",
    "twoway (line sigma t), ///\n",
    "    title(\"GARCH(1,1): Conditional Volatility sigma_t\") ///\n",
    "    ytitle(\"sigma_t\") xtitle(\"Time\") ///\n",
    "    name(ts_garch_vol, replace)\n",
    "\n",
    "* Overlay returns and volatility\n",
    "twoway (line r t, yaxis(1)) (line sigma t, yaxis(2)), ///\n",
    "    title(\"GARCH(1,1): Returns and Volatility\") ///\n",
    "    ytitle(\"Returns\", axis(1)) ytitle(\"Volatility\", axis(2)) ///\n",
    "    xtitle(\"Time\") ///\n",
    "    legend(label(1 \"r_t\") label(2 \"sigma_t\")) ///\n",
    "    name(ts_garch_both, replace)\n",
    "\n",
    "* Autocorrelation of squared returns\n",
    "generate r2 = r^2\n",
    "ac r2, lags(20) name(acf_garch_r2, replace)\n",
    "\n",
    "display \"\"\n",
    "display \"GARCH(1,1) shows stronger persistence than ARCH(1):\"\n",
    "display \"Volatility persists through beta_1 * sigma_{t-1}^2 term\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce9a218",
   "metadata": {},
   "source": [
    "### 2.3 Multivariate GARCH\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate a bivariate GARCH model to demonstrate **time-varying correlations** between assets. We'll use the Constant Conditional Correlation (CCC) model, which allows each asset to have its own GARCH process while maintaining a constant correlation structure.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Multivariate GARCH** models extend univariate GARCH to multiple assets, allowing for:\n",
    "- **Time-varying variances** for each asset (via individual GARCH processes)\n",
    "- **Time-varying correlations** between assets (in more advanced models like DCC)\n",
    "\n",
    "**CCC-GARCH Model**:\n",
    "\n",
    "The **Constant Conditional Correlation (CCC)** model assumes:\n",
    "\n",
    "$$\\mathbf{r}_t = \\boldsymbol{\\mu} + \\boldsymbol{\\varepsilon}_t$$\n",
    "\n",
    "where $\\boldsymbol{\\varepsilon}_t$ has conditional covariance matrix:\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{D}_t \\mathbf{R} \\mathbf{D}_t$$\n",
    "\n",
    "where:\n",
    "- $\\mathbf{D}_t = \\text{diag}(\\sigma_{1t}, \\sigma_{2t})$ is a diagonal matrix of conditional standard deviations\n",
    "- $\\mathbf{R}$ is a **constant** correlation matrix\n",
    "- Each $\\sigma_{it}^2$ follows its own GARCH(1,1) process\n",
    "\n",
    "**DCC-GARCH Model**:\n",
    "\n",
    "The **Dynamic Conditional Correlation (DCC)** model allows correlations to vary:\n",
    "\n",
    "$$\\mathbf{H}_t = \\mathbf{D}_t \\mathbf{R}_t \\mathbf{D}_t$$\n",
    "\n",
    "where $\\mathbf{R}_t$ is a **time-varying** correlation matrix that follows a GARCH-like process.\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: Multivariate GARCH models are essential for portfolio risk management because they capture how correlations between assets change over time, especially during crisis periods when correlations tend to increase (correlation clustering).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Number of observations (_N) was 0, now 1,000.\n",
      "\n",
      "\n",
      "\n",
      "Time variable: t, 1 to 1000\n",
      "        Delta: 1 unit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "(1,000 missing values generated)\n",
      "\n",
      "\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(1 real change made)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "(999 missing values generated)\n",
      "\n",
      "\n",
      ". generate sigma1 = sqrt(sigma2_1)\n",
      "(998 missing values generated)\n",
      "\n",
      ". generate sigma2 = sqrt(sigma2_2)\n",
      "(998 missing values generated)\n",
      "\n",
      ". generate corr_t = rho  \n",
      "\n",
      ". cap noi twoway (line r1 t) (line r2 t),     title(\"Bivariate GARCH: Returns\") \n",
      ">     ytitle(\"Returns\") xtitle(\"Time\")     legend(label(1 \"r1_t\") label(2 \"r2_t\"\n",
      "> ))     name(ts_mgarch_ret, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph11.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph11.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line sigma1 t) (line sigma2 t),     title(\"Bivariate GARCH: Co\n",
      "> nditional Volatilities\")     ytitle(\"Volatility\") xtitle(\"Time\")     legend(la\n",
      "> bel(1 \"sigma_1t\") label(2 \"sigma_2t\"))     name(ts_mgarch_vol, replace)\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph12.svg saved as SVG\n",
      "    format\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph12.pdf saved as PDF\n",
      "    format\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". cap noi twoway (line corr_t t),     title(\"Constant Conditional Correlation (C\n",
      "> CC)\")     ytitle(\"Correlation\") xtitle(\"Time\")     yline(rho, lcolor(red) lpat\n",
      "> tern(dash))     name(ts_mgarch_corr, replace)\n",
      "invalid line argument, rho\n",
      "\n",
      ". if _rc == 0 {\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.svg\"', width(600) replace\n",
      ".     noi gr export `\"/Users/jesusvillotamiranda/.stata_kernel_cache/graph$stata\n",
      "> _kernel_graph_counter.pdf\"', replace\n",
      ".     global stata_kernel_graph_counter = $stata_kernel_graph_counter + 1\n",
      ". }            \n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"Summary Statistics for Bivariate GARCH:\"\n",
      "Summary Statistics for Bivariate GARCH:\n",
      "\n",
      ". summarize r1 r2 sigma1 sigma2, detail\n",
      "\n",
      "                             r1\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%    -.0017978      -.0017978\n",
      " 5%    -.0017978          .9592\n",
      "10%    -.0017978              .       Obs                   2\n",
      "25%    -.0017978              .       Sum of wgt.           2\n",
      "\n",
      "50%     .4787011                      Mean           .4787011\n",
      "                        Largest       Std. dev.       .679528\n",
      "75%        .9592              .\n",
      "90%        .9592              .       Variance       .4617584\n",
      "95%        .9592      -.0017978       Skewness              0\n",
      "99%        .9592          .9592       Kurtosis              1\n",
      "\n",
      "                             r2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .0198187       .0198187\n",
      " 5%     .0198187       1.638181\n",
      "10%     .0198187              .       Obs                   2\n",
      "25%     .0198187              .       Sum of wgt.           2\n",
      "\n",
      "50%         .829                      Mean               .829\n",
      "                        Largest       Std. dev.      1.144355\n",
      "75%     1.638181              .\n",
      "90%     1.638181              .       Variance       1.309549\n",
      "95%     1.638181       .0198187       Skewness              0\n",
      "99%     1.638181       1.638181       Kurtosis              1\n",
      "\n",
      "                           sigma1\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     .9959952       .9959952\n",
      " 5%     .9959952              1\n",
      "10%     .9959952              .       Obs                   2\n",
      "25%     .9959952              .       Sum of wgt.           2\n",
      "\n",
      "50%     .9979976                      Mean           .9979976\n",
      "                        Largest       Std. dev.      .0028318\n",
      "75%            1              .\n",
      "90%            1              .       Variance       8.02e-06\n",
      "95%            1       .9959952       Skewness              0\n",
      "99%            1              1       Kurtosis              1\n",
      "\n",
      "                           sigma2\n",
      "-------------------------------------------------------------\n",
      "      Percentiles      Smallest\n",
      " 1%     1.264911       1.264911\n",
      " 5%     1.264911       1.327609\n",
      "10%     1.264911              .       Obs                   2\n",
      "25%     1.264911              .       Sum of wgt.           2\n",
      "\n",
      "50%      1.29626                      Mean            1.29626\n",
      "                        Largest       Std. dev.      .0443342\n",
      "75%     1.327609              .\n",
      "90%     1.327609              .       Variance       .0019655\n",
      "95%     1.327609       1.264911       Skewness              0\n",
      "99%     1.327609       1.327609       Kurtosis              1\n",
      "\n",
      ". display \"\"\n",
      "\n",
      "\n",
      ". display \"Constant correlation rho = \" %6.4f rho\n",
      "Constant correlation rho = 0.6000\n"
     ]
    }
   ],
   "source": [
    "* ============================================================================\n",
    "* Simulation 7: Multivariate GARCH (CCC Model)\n",
    "* ============================================================================\n",
    "* Simulate bivariate GARCH with constant correlation\n",
    "* Each asset has its own GARCH(1,1) process, but correlation is constant\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set GARCH parameters for asset 1\n",
    "scalar mu1 = 0.0  // Mean return for asset 1\n",
    "scalar omega1 = 0.05  // GARCH intercept for asset 1\n",
    "scalar alpha1_1 = 0.1  // ARCH coefficient for asset 1\n",
    "scalar beta1_1 = 0.85  // GARCH coefficient for asset 1\n",
    "\n",
    "* Set GARCH parameters for asset 2\n",
    "scalar mu2 = 0.0  // Mean return for asset 2\n",
    "scalar omega2 = 0.08  // GARCH intercept for asset 2\n",
    "scalar alpha1_2 = 0.15  // ARCH coefficient for asset 2\n",
    "scalar beta1_2 = 0.8  // GARCH coefficient for asset 2\n",
    "\n",
    "* Constant correlation\n",
    "scalar rho = 0.6  // Constant correlation between assets\n",
    "\n",
    "* Generate correlated standard normal innovations using Cholesky\n",
    "* Correlation matrix R = [1  rho; rho  1]\n",
    "* Cholesky: L = [1  0; rho  sqrt(1-rho^2)]\n",
    "scalar L11 = 1\n",
    "scalar L21 = rho\n",
    "scalar L22 = sqrt(1 - rho^2)\n",
    "\n",
    "generate z1_indep = rnormal()  // Independent standard normal 1\n",
    "generate z2_indep = rnormal()  // Independent standard normal 2\n",
    "\n",
    "* Generate correlated innovations\n",
    "generate z1 = L11 * z1_indep  // Correlated z1\n",
    "generate z2 = L21 * z1_indep + L22 * z2_indep  // Correlated z2\n",
    "\n",
    "* Initialize GARCH processes\n",
    "generate sigma2_1 = .  // Conditional variance for asset 1\n",
    "generate sigma2_2 = .  // Conditional variance for asset 2\n",
    "generate epsilon1 = .  // Innovation for asset 1\n",
    "generate epsilon2 = .  // Innovation for asset 2\n",
    "generate r1 = .  // Return for asset 1\n",
    "generate r2 = .  // Return for asset 2\n",
    "\n",
    "* Unconditional variances\n",
    "scalar sigma2_1_uncond = omega1 / (1 - alpha1_1 - beta1_1)\n",
    "scalar sigma2_2_uncond = omega2 / (1 - alpha1_2 - beta1_2)\n",
    "\n",
    "* Set initial conditions\n",
    "replace sigma2_1 = sigma2_1_uncond if t == 1\n",
    "replace sigma2_2 = sigma2_2_uncond if t == 1\n",
    "replace epsilon1 = sqrt(sigma2_1) * z1 if t == 1\n",
    "replace epsilon2 = sqrt(sigma2_2) * z2 if t == 1\n",
    "replace r1 = mu1 + epsilon1 if t == 1\n",
    "replace r2 = mu2 + epsilon2 if t == 1\n",
    "\n",
    "* Generate lagged terms\n",
    "generate eps2_1_lag1 = L.epsilon1^2\n",
    "generate eps2_2_lag1 = L.epsilon2^2\n",
    "generate sigma2_1_lag1 = L.sigma2_1\n",
    "generate sigma2_2_lag1 = L.sigma2_2\n",
    "\n",
    "* Recursively generate bivariate GARCH\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        * GARCH(1,1) for asset 1\n",
    "        replace sigma2_1 = omega1 + alpha1_1 * eps2_1_lag1 + beta1_1 * sigma2_1_lag1 if t == `i'\n",
    "        * GARCH(1,1) for asset 2\n",
    "        replace sigma2_2 = omega2 + alpha1_2 * eps2_2_lag1 + beta1_2 * sigma2_2_lag1 if t == `i'\n",
    "        * Innovations (correlated)\n",
    "        replace epsilon1 = sqrt(sigma2_1) * z1 if t == `i'\n",
    "        replace epsilon2 = sqrt(sigma2_2) * z2 if t == `i'\n",
    "        * Returns\n",
    "        replace r1 = mu1 + epsilon1 if t == `i'\n",
    "        replace r2 = mu2 + epsilon2 if t == `i'\n",
    "        * Update lagged terms\n",
    "        replace eps2_1_lag1 = L.epsilon1^2 if t == `i'\n",
    "        replace eps2_2_lag1 = L.epsilon2^2 if t == `i'\n",
    "        replace sigma2_1_lag1 = L.sigma2_1 if t == `i'\n",
    "        replace sigma2_2_lag1 = L.sigma2_2 if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate conditional standard deviations\n",
    "generate sigma1 = sqrt(sigma2_1)\n",
    "generate sigma2 = sqrt(sigma2_2)\n",
    "\n",
    "* Time-varying correlation (constant in CCC, but we compute it)\n",
    "generate corr_t = rho  // Constant correlation in CCC model\n",
    "\n",
    "* Time series plots\n",
    "twoway (line r1 t) (line r2 t), ///\n",
    "    title(\"Bivariate GARCH: Returns\") ///\n",
    "    ytitle(\"Returns\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"r1_t\") label(2 \"r2_t\")) ///\n",
    "    name(ts_mgarch_ret, replace)\n",
    "\n",
    "twoway (line sigma1 t) (line sigma2 t), ///\n",
    "    title(\"Bivariate GARCH: Conditional Volatilities\") ///\n",
    "    ytitle(\"Volatility\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"sigma_1t\") label(2 \"sigma_2t\")) ///\n",
    "    name(ts_mgarch_vol, replace)\n",
    "\n",
    "twoway (line corr_t t), ///\n",
    "    title(\"Constant Conditional Correlation (CCC)\") ///\n",
    "    ytitle(\"Correlation\") xtitle(\"Time\") ///\n",
    "    yline(rho, lcolor(red) lpattern(dash)) ///\n",
    "    name(ts_mgarch_corr, replace)\n",
    "\n",
    "* Summary statistics\n",
    "display \"\"\n",
    "display \"Summary Statistics for Bivariate GARCH:\"\n",
    "summarize r1 r2 sigma1 sigma2, detail\n",
    "\n",
    "display \"\"\n",
    "display \"Constant correlation rho = \" %6.4f rho\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367ee3c2",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Individual Volatility Dynamics**: Each asset has its own GARCH process, so their volatilities evolve independently (though they're correlated through innovations).\n",
    "\n",
    "2. **Constant Correlation**: The CCC model assumes correlation is constant over time. In practice, correlations often increase during crisis periods, which is why DCC models are preferred.\n",
    "\n",
    "3. **Portfolio Implications**: Even with constant correlation, the time-varying volatilities mean that portfolio risk changes over time, requiring dynamic risk management.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: Multivariate GARCH models are essential for understanding how risks evolve in portfolios. They capture both individual asset volatility dynamics and the relationships between assets, making them crucial for risk management and portfolio optimization.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb887301",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"../notebook_styles.css\">\n",
    "\n",
    "<a id=\"section-3\"></a>\n",
    "<h2 class=\"styled-header\">3) Kalman Filter Simulations</h2>\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç Conceptual Foundation**: The **Kalman filter** is an algorithm for estimating unobserved (latent) states in state-space models. It's widely used in economics and finance for:\n",
    "- **Filtering**: Estimating current state given all past and current observations\n",
    "- **Smoothing**: Estimating past states given all available data\n",
    "- **Forecasting**: Predicting future states and observations\n",
    "\n",
    "</div>\n",
    "\n",
    "**State-Space Models** have two equations:\n",
    "\n",
    "1. **State equation**: Describes how the unobserved state evolves\n",
    "   $$x_t = F x_{t-1} + w_t, \\quad w_t \\sim N(0, Q)$$\n",
    "\n",
    "2. **Observation equation**: Describes how observations relate to the state\n",
    "   $$y_t = H x_t + v_t, \\quad v_t \\sim N(0, R)$$\n",
    "\n",
    "**Key Applications**:\n",
    "- **Signal extraction**: Separating signal from noise\n",
    "- **Time-varying parameters**: Estimating parameters that change over time\n",
    "- **Dynamic factor models**: Extracting common factors from multiple series\n",
    "- **GDP nowcasting**: Combining multiple data sources in real-time\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Why This Matters**: The Kalman filter provides optimal (in the mean-squared error sense) estimates of unobserved states. It's the foundation for many advanced time series models and is essential for real-time data analysis and forecasting.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01c1429",
   "metadata": {},
   "source": [
    "### 3.1 Basic Kalman Filter\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate a simple state-space model (random walk plus noise) and apply the Kalman filter to estimate the unobserved state. This demonstrates the basic filtering mechanism.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Random Walk Plus Noise Model**:\n",
    "\n",
    "- **State equation**: $x_t = x_{t-1} + w_t$, where $w_t \\sim N(0, Q)$ (random walk)\n",
    "- **Observation equation**: $y_t = x_t + v_t$, where $v_t \\sim N(0, R)$ (state plus measurement error)\n",
    "\n",
    "This model is useful for:\n",
    "- **Signal extraction**: $x_t$ is the \"true\" signal, $y_t$ is the noisy observation\n",
    "- **Trend estimation**: $x_t$ represents the underlying trend\n",
    "\n",
    "**Kalman Filter Algorithm**:\n",
    "\n",
    "1. **Prediction step**: Predict state and covariance given past information\n",
    "   $$\\hat{x}_{t|t-1} = F \\hat{x}_{t-1|t-1}$$\n",
    "   $$P_{t|t-1} = F P_{t-1|t-1} F' + Q$$\n",
    "\n",
    "2. **Update step**: Update estimates given new observation\n",
    "   $$K_t = P_{t|t-1} H' (H P_{t|t-1} H' + R)^{-1}$$ (Kalman gain)\n",
    "   $$\\hat{x}_{t|t} = \\hat{x}_{t|t-1} + K_t (y_t - H \\hat{x}_{t|t-1})$$\n",
    "   $$P_{t|t} = (I - K_t H) P_{t|t-1}$$\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: The Kalman filter optimally combines predictions with observations, weighting them by their relative uncertainties. When observation noise is small ($R$ small), the filter trusts observations more. When state noise is small ($Q$ small), the filter trusts predictions more.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "* ============================================================================\n",
    "* Simulation 8: Basic Kalman Filter (Random Walk Plus Noise)\n",
    "* ============================================================================\n",
    "* State: x_t = x_{t-1} + w_t, w_t ~ N(0, Q)\n",
    "* Observation: y_t = x_t + v_t, v_t ~ N(0, R)\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set parameters\n",
    "scalar Q = 0.1  // State noise variance (process noise)\n",
    "scalar R = 1.0  // Observation noise variance (measurement error)\n",
    "scalar F = 1.0  // State transition (random walk: F = 1)\n",
    "scalar H = 1.0  // Observation matrix (direct observation: H = 1)\n",
    "\n",
    "* Generate state noise\n",
    "generate w = rnormal(0, sqrt(Q))  // State innovation w_t ~ N(0, Q)\n",
    "\n",
    "* Generate observation noise\n",
    "generate v = rnormal(0, sqrt(R))  // Observation error v_t ~ N(0, R)\n",
    "\n",
    "* Initialize and generate true state (random walk)\n",
    "generate x_true = .  // True (unobserved) state\n",
    "replace x_true = 0 if t == 1  // Initial condition\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        replace x_true = L.x_true + w if t == `i'  // Random walk: x_t = x_{t-1} + w_t\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate observations (state plus noise)\n",
    "generate y = x_true + v  // Observation: y_t = x_t + v_t\n",
    "\n",
    "* Kalman Filter Implementation\n",
    "* Initialize\n",
    "generate x_filtered = .  // Filtered state estimate\n",
    "generate P = .  // State covariance\n",
    "replace x_filtered = 0 if t == 1  // Initial state estimate\n",
    "replace P = 1.0 if t == 1  // Initial covariance (prior uncertainty)\n",
    "\n",
    "* Kalman filter recursion\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        * Prediction step\n",
    "        scalar x_pred = F * L.x_filtered  // Predicted state\n",
    "        scalar P_pred = F * L.P * F + Q  // Predicted covariance\n",
    "        \n",
    "        * Update step\n",
    "        scalar K = P_pred * H / (H * P_pred * H + R)  // Kalman gain\n",
    "        scalar x_update = x_pred + K * (y - H * x_pred)  // Updated state\n",
    "        scalar P_update = (1 - K * H) * P_pred  // Updated covariance\n",
    "        \n",
    "        * Store results\n",
    "        replace x_filtered = x_update if t == `i'\n",
    "        replace P = P_update if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate confidence bands (filtered estimate ¬± 2 standard errors)\n",
    "generate se = sqrt(P)  // Standard error of filtered estimate\n",
    "generate x_lower = x_filtered - 2 * se  // Lower confidence band\n",
    "generate x_upper = x_filtered + 2 * se  // Upper confidence band\n",
    "\n",
    "* Time series plots\n",
    "twoway (line y t, lcolor(gs10)) (line x_true t, lcolor(blue)) ///\n",
    "    (line x_filtered t, lcolor(red) lpattern(dash)), ///\n",
    "    title(\"Kalman Filter: True State, Observations, and Filtered Estimate\") ///\n",
    "    ytitle(\"Value\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"Observations y_t\") label(2 \"True state x_t\") label(3 \"Filtered x_{t|t}\")) ///\n",
    "    name(kf_basic, replace)\n",
    "\n",
    "twoway (rarea x_lower x_upper t, color(gs12)) ///\n",
    "    (line x_true t, lcolor(blue)) ///\n",
    "    (line x_filtered t, lcolor(red) lpattern(dash)), ///\n",
    "    title(\"Kalman Filter with Confidence Bands\") ///\n",
    "    ytitle(\"State\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"95% CI\") label(2 \"True state\") label(3 \"Filtered\")) ///\n",
    "    name(kf_bands, replace)\n",
    "\n",
    "* Summary statistics\n",
    "display \"\"\n",
    "display \"Summary Statistics:\"\n",
    "summarize x_true y x_filtered, detail\n",
    "\n",
    "* Mean squared error\n",
    "generate mse = (x_filtered - x_true)^2\n",
    "summarize mse, meanonly\n",
    "display \"\"\n",
    "display \"Mean Squared Error of Filtered Estimate: \" %6.4f r(mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9cf356",
   "metadata": {},
   "source": [
    "#### Interpretation of Results\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Analysis Reveals:**\n",
    "\n",
    "1. **Filtering Performance**: The filtered estimate (`x_filtered`) should track the true state (`x_true`) closely, with the observations (`y`) showing more noise around the true state.\n",
    "\n",
    "2. **Uncertainty Quantification**: The confidence bands show the uncertainty in the filtered estimate. Wider bands indicate higher uncertainty (e.g., when observation noise is large).\n",
    "\n",
    "3. **Kalman Gain**: The Kalman gain determines how much weight to put on new observations vs. predictions. When $R$ is small (precise observations), the gain is large and the filter trusts observations more.\n",
    "\n",
    "4. **Smoothing Effect**: The filtered estimate is \"smoother\" than the observations because it optimally combines information from all past observations.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: The Kalman filter provides optimal estimates of unobserved states by optimally combining predictions with observations. It's the foundation for many advanced time series models and real-time data analysis.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f2e4c",
   "metadata": {},
   "source": [
    "### 3.2 AR(1) with Measurement Error\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate an AR(1) state process with noisy observations and use the Kalman filter to recover the true state. This demonstrates how the filter handles measurement error.\n",
    "\n",
    "</div>\n",
    "\n",
    "**AR(1) State with Measurement Error**:\n",
    "\n",
    "- **State equation**: $x_t = \\phi x_{t-1} + w_t$, where $w_t \\sim N(0, Q)$ (AR(1) process)\n",
    "- **Observation equation**: $y_t = x_t + v_t$, where $v_t \\sim N(0, R)$ (state plus measurement error)\n",
    "\n",
    "This model is useful when:\n",
    "- The true process is AR(1) but observations are contaminated with noise\n",
    "- We want to extract the \"signal\" from noisy data\n",
    "- Economic variables are measured with error\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: The Kalman filter optimally separates the AR(1) signal from measurement noise, providing better estimates than simple smoothing techniques.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "* ============================================================================\n",
    "* Simulation 9: AR(1) State with Measurement Error\n",
    "* ============================================================================\n",
    "* State: x_t = phi * x_{t-1} + w_t, w_t ~ N(0, Q)\n",
    "* Observation: y_t = x_t + v_t, v_t ~ N(0, R)\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Set parameters\n",
    "scalar phi = 0.8  // AR(1) coefficient (stationary: |phi| < 1)\n",
    "scalar Q = 0.1  // State noise variance\n",
    "scalar R = 0.5  // Observation noise variance\n",
    "scalar F = phi  // State transition matrix\n",
    "scalar H = 1.0  // Observation matrix\n",
    "\n",
    "* Generate state noise\n",
    "generate w = rnormal(0, sqrt(Q))  // State innovation\n",
    "\n",
    "* Generate observation noise\n",
    "generate v = rnormal(0, sqrt(R))  // Observation error\n",
    "\n",
    "* Initialize and generate true AR(1) state\n",
    "generate x_true = .  // True state\n",
    "replace x_true = 0 if t == 1  // Initial condition\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        replace x_true = phi * L.x_true + w if t == `i'  // AR(1): x_t = phi * x_{t-1} + w_t\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate noisy observations\n",
    "generate y = x_true + v  // Observation: y_t = x_t + v_t\n",
    "\n",
    "* Kalman Filter\n",
    "generate x_filtered = .  // Filtered estimate\n",
    "generate P = .  // State covariance\n",
    "replace x_filtered = 0 if t == 1  // Initial estimate\n",
    "replace P = 1.0 if t == 1  // Initial covariance\n",
    "\n",
    "* Kalman filter recursion\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        * Prediction\n",
    "        scalar x_pred = F * L.x_filtered\n",
    "        scalar P_pred = F * L.P * F + Q\n",
    "        * Update\n",
    "        scalar K = P_pred * H / (H * P_pred * H + R)\n",
    "        scalar x_update = x_pred + K * (y - H * x_pred)\n",
    "        scalar P_update = (1 - K * H) * P_pred\n",
    "        * Store\n",
    "        replace x_filtered = x_update if t == `i'\n",
    "        replace P = P_update if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Confidence bands\n",
    "generate se = sqrt(P)\n",
    "generate x_lower = x_filtered - 2 * se\n",
    "generate x_upper = x_filtered + 2 * se\n",
    "\n",
    "* Plots\n",
    "twoway (line y t, lcolor(gs10)) (line x_true t, lcolor(blue)) ///\n",
    "    (line x_filtered t, lcolor(red) lpattern(dash)), ///\n",
    "    title(\"AR(1) State with Measurement Error: Kalman Filter\") ///\n",
    "    ytitle(\"Value\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"Observations y_t\") label(2 \"True state x_t\") label(3 \"Filtered\")) ///\n",
    "    name(kf_ar1, replace)\n",
    "\n",
    "display \"\"\n",
    "display \"AR(1) coefficient phi = \" %6.4f phi\n",
    "display \"Measurement error variance R = \" %6.4f R\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f96798",
   "metadata": {},
   "source": [
    "### 3.3 Time-Varying Parameter Model\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Objective**: Simulate a regression model with time-varying coefficients and use the Kalman filter to estimate how parameters evolve over time. This demonstrates the filter's ability to track changing relationships.\n",
    "\n",
    "</div>\n",
    "\n",
    "**Time-Varying Parameter Model**:\n",
    "\n",
    "- **State equation**: $\\beta_t = \\beta_{t-1} + w_t$, where $w_t \\sim N(0, Q)$ (coefficients follow random walk)\n",
    "- **Observation equation**: $y_t = x_t' \\beta_t + v_t$, where $v_t \\sim N(0, R)$ (regression with time-varying coefficients)\n",
    "\n",
    "This model is useful for:\n",
    "- **Structural breaks**: When relationships change over time\n",
    "- **Policy analysis**: When policy effects evolve\n",
    "- **Financial models**: When risk-return relationships change\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: The Kalman filter allows us to estimate time-varying parameters, capturing how economic relationships evolve over time. This is essential when parameters are not constant (structural breaks, regime changes).\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "* ============================================================================\n",
    "* Simulation 10: Time-Varying Parameter Model\n",
    "* ============================================================================\n",
    "* State: beta_t = beta_{t-1} + w_t (time-varying coefficient)\n",
    "* Observation: y_t = x_t * beta_t + v_t (regression with TVP)\n",
    "\n",
    "clear all  // Clear memory and remove all variables\n",
    "set seed 12345  // Set random seed for reproducibility\n",
    "set obs 1000  // Set number of observations to 1000\n",
    "\n",
    "* Generate time index\n",
    "generate t = _n  // Create time index variable\n",
    "tsset t  // Declare time series structure\n",
    "\n",
    "* Generate regressor (exogenous variable)\n",
    "generate x = rnormal(0, 1)  // Regressor x_t\n",
    "\n",
    "* Set parameters\n",
    "scalar Q = 0.01  // State noise variance (small = slow parameter change)\n",
    "scalar R = 0.5  // Observation noise variance\n",
    "scalar F = 1.0  // State transition (random walk)\n",
    "scalar beta0 = 1.0  // Initial coefficient value\n",
    "\n",
    "* Generate state noise\n",
    "generate w = rnormal(0, sqrt(Q))  // Coefficient innovation\n",
    "\n",
    "* Generate observation noise\n",
    "generate v = rnormal(0, sqrt(R))  // Regression error\n",
    "\n",
    "* Initialize and generate true time-varying coefficient\n",
    "generate beta_true = .  // True coefficient\n",
    "replace beta_true = beta0 if t == 1  // Initial value\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        replace beta_true = L.beta_true + w if t == `i'  // Random walk: beta_t = beta_{t-1} + w_t\n",
    "    }\n",
    "}\n",
    "\n",
    "* Generate observations (regression with time-varying coefficient)\n",
    "generate y = x * beta_true + v  // Observation: y_t = x_t * beta_t + v_t\n",
    "\n",
    "* Kalman Filter for time-varying parameter\n",
    "generate beta_filtered = .  // Filtered coefficient estimate\n",
    "generate P = .  // Coefficient covariance\n",
    "replace beta_filtered = beta0 if t == 1  // Initial estimate\n",
    "replace P = 1.0 if t == 1  // Initial covariance\n",
    "\n",
    "* Kalman filter recursion\n",
    "quietly {\n",
    "    forvalues i = 2/1000 {\n",
    "        * Prediction\n",
    "        scalar beta_pred = F * L.beta_filtered\n",
    "        scalar P_pred = F * L.P * F + Q\n",
    "        * Update (H = x_t, observation matrix is time-varying)\n",
    "        scalar H_t = x  // Observation matrix depends on regressor\n",
    "        scalar K = P_pred * H_t / (H_t * P_pred * H_t + R)\n",
    "        scalar beta_update = beta_pred + K * (y - H_t * beta_pred)\n",
    "        scalar P_update = (1 - K * H_t) * P_pred\n",
    "        * Store\n",
    "        replace beta_filtered = beta_update if t == `i'\n",
    "        replace P = P_update if t == `i'\n",
    "    }\n",
    "}\n",
    "\n",
    "* Confidence bands\n",
    "generate se = sqrt(P)\n",
    "generate beta_lower = beta_filtered - 2 * se\n",
    "generate beta_upper = beta_filtered + 2 * se\n",
    "\n",
    "* Plots\n",
    "twoway (line beta_true t, lcolor(blue)) ///\n",
    "    (line beta_filtered t, lcolor(red) lpattern(dash)) ///\n",
    "    (rarea beta_lower beta_upper t, color(gs12)), ///\n",
    "    title(\"Time-Varying Parameter: True and Filtered Coefficient\") ///\n",
    "    ytitle(\"Coefficient\") xtitle(\"Time\") ///\n",
    "    legend(label(1 \"True beta_t\") label(2 \"Filtered\") label(3 \"95% CI\")) ///\n",
    "    name(kf_tvp, replace)\n",
    "\n",
    "display \"\"\n",
    "display \"Time-Varying Parameter Model:\"\n",
    "display \"Coefficient follows random walk with innovation variance Q = \" %6.4f Q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870c854a",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 20px; text-align: center; border-bottom: 2px solid #e5e7eb;\">\n",
    "  <a href=\"1_2_arma_models.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: linear-gradient(180deg, #38549c 0%, #14276c 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; box-shadow: 0 4px 12px rgba(56,84,156,0.3); margin-right: 10px;\">\n",
    "    ‚Üê Session 1: ARMA Models\n",
    "  </a>\n",
    "  <a href=\"2_3_gdp_gdi.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: linear-gradient(180deg, #38549c 0%, #14276c 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; box-shadow: 0 4px 12px rgba(56,84,156,0.3);\">\n",
    "    GDP and GDI Analysis ‚Üí\n",
    "  </a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec021ac8",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 20px; text-align: center; border-bottom: 2px solid #e5e7eb;\">\n",
    "  <a href=\"06_simul_kalman.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: linear-gradient(180deg, #38549c 0%, #14276c 100%); color: white; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; box-shadow: 0 4px 12px rgba(56,84,156,0.3);\">\n",
    "    Part 2 - Kalman Filter Simulations ‚Üí\n",
    "  </a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata",
   "language": "stata",
   "name": "stata"
  },
  "language_info": {
   "codemirror_mode": "stata",
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
