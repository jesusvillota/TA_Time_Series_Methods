{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 20px; text-align: center; border-bottom: 2px solid #e5e7eb;\">\n",
    "  <a href=\"1_1_simul_univariate.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: #f9fafb; color: #38549c; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; border: 1px solid #e5e7eb; margin-right: 12px;\">\n",
    "    ‚Üê Part 1 - Univariate Time Series Model Simulations\n",
    "  </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 880px; margin: 20px auto 22px; padding: 0px; border-radius: 18px; border: 1px solid #e5e7eb; background: linear-gradient(180deg, #ffffff 0%, #f9fafb 100%); box-shadow: 0 8px 26px rgba(0,0,0,0.06); overflow: hidden;\">\n",
    "  <div style=\"padding: 34px 32px 14px; text-align: center; line-height: 1.38;\">\n",
    "    <div style=\"font-size: 13px; letter-spacing: 0.14em; text-transform: uppercase; color: #6b7280; font-weight: bold; margin-bottom: 5px;\">\n",
    "      Session #1 ‚Ä¢ Part 2\n",
    "    </div>\n",
    "    <!-- <div style=\"font-size: 29px; font-weight: 800; color: #14276c; margin-bottom: 4px;\">\n",
    "      Linear Time Series Models\n",
    "    </div> -->\n",
    "    <div style=\"font-size: 29px; font-weight: 800; color: #14276c; margin-bottom: 4px;\">\n",
    "      ARMA Model Estimation and Selection\n",
    "    </div>\n",
    "    <div style=\"font-size: 16.5px; color: #374151; font-style: italic; margin-bottom: 0;\">\n",
    "      Advanced Training School: Methods for Time Series\n",
    "    </div>\n",
    "  </div>\n",
    "  <div style=\"background: none; text-align: center; margin: 30px 0 10px;\">\n",
    "    <img src=\"https://www.cemfi.es/images/Logo-Azul.png\" alt=\"CEMFI Logo\" style=\"width: 158px; filter: drop-shadow(0 2px 12px rgba(56,84,156,0.05)); margin-bottom: 0;\">\n",
    "  </div>\n",
    "  <div style=\"font-family: 'Times New Roman', Times, serif; color: #38549c; text-align: center; font-size: 1.22em; font-weight: bold; margin-bottom: 0px;\">\n",
    "    Jesus Villota Miranda ¬© 2025\n",
    "  </div>\n",
    "  <div style=\"font-family: 'Times New Roman', Times, serif; color: #38549c; text-align: center; font-size: 1em; margin-top: 7px; margin-bottom: 20px;\">\n",
    "    <a href=\"mailto:jesus.villota@cemfi.edu.es\" style=\"color: #38549c; text-decoration: none; margin-right:8px;\">jesus.villota@cemfi.edu.es</a>\n",
    "    <span style=\"color:#9fa7bd;\">|</span>\n",
    "    <a href=\"https://www.linkedin.com/in/jesusvillotamiranda/\" target=\"_blank\" style=\"color: #38549c; text-decoration: none; margin-left:7px;\">LinkedIn</a>\n",
    "  </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 24px 32px; border-radius: 18px; border: 1px solid #e5e7eb; background: linear-gradient(180deg, #ffffff 0%, #f9fafb 100%); box-shadow: 0 8px 26px rgba(0,0,0,0.06);\">\n",
    "<!-- <div style=\"font-size: 14px; letter-spacing: 0.1em; text-transform: uppercase; color: #6b7280; font-weight: bold; margin-bottom: 12px; text-align: center;\">Session #1 ‚Ä¢ Part II</div> -->\n",
    "<div style=\"font-size: 22px; font-weight: 700; color: #14276c; margin-bottom: 16px; text-align: center;\">Table of Contents</div><div style=\"font-size: 15px; color: #374151; line-height: 1.8;\"><div style=\"margin-bottom: 12px;\"><strong>1.</strong> <a href=\"#section-1\" style=\"color: #38549c; text-decoration: none;\">Introduction to ARMA Models</a></div><div style=\"margin-bottom: 12px;\"><strong>2.</strong> <a href=\"#section-2\" style=\"color: #38549c; text-decoration: none;\"> Modeling the VIX Index</a></div><div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.1 VIX Historical Evolution and Distribution</div><div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.2 Log-VIX Transformation</div><div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.3 Unit Root Testing</div><div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.4 ARMA Model Selection (AIC/BIC)</div><div style=\"margin-left: 20px; margin-bottom: 8px; font-size: 14px;\">2.5 ARMA(2,1) Estimation</div><div style=\"margin-left: 20px; margin-bottom: 0px; font-size: 14px;\">2.6 Residual Diagnostics</div></div></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"notebook_styles.css\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"../notebook_styles.css\">\n",
    "\n",
    "<a id=\"section-1\"></a>\n",
    "<h2 class=\"styled-header\">1) Introduction to ARMA Models</h2>\n",
    "\n",
    "**ARMA(p,q)** models combine autoregressive (AR) and moving average (MA) components to capture both the persistence and shock dynamics in time series data:\n",
    "\n",
    "$$\n",
    "Y_t = \\phi_1 Y_{t-1} + \\cdots + \\phi_p Y_{t-p} + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\cdots + \\theta_q \\varepsilon_{t-q}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $Y_t$ is the time series at time $t$\n",
    "- $\\phi_1, \\ldots, \\phi_p$ are the **autoregressive coefficients** (capture persistence from past values)\n",
    "- $\\theta_1, \\ldots, \\theta_q$ are the **moving average coefficients** (capture impact of past shocks)\n",
    "- $\\varepsilon_t$ is white noise with $E[\\varepsilon_t] = 0$ and $\\text{Var}(\\varepsilon_t) = \\sigma^2$\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç Why ARMA Models?**\n",
    "\n",
    "ARMA models provide a **parsimonious** way to represent complex autocorrelation patterns:\n",
    "- **AR component**: Captures direct dependence on past values (long memory)\n",
    "- **MA component**: Captures dependence on past forecast errors (smoothing)\n",
    "- **Combined**: Can approximate a wide range of stationary processes with fewer parameters than pure AR or MA models\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Model Selection: Information Criteria\n",
    "\n",
    "To determine optimal lag orders $(p, q)$, we use **information criteria** that balance model fit against complexity:\n",
    "\n",
    "**Akaike Information Criterion (AIC)**:\n",
    "$$\n",
    "\\text{AIC} = -2\\ln(L) + 2k\n",
    "$$\n",
    "\n",
    "**Bayesian Information Criterion (BIC)**:\n",
    "$$\n",
    "\\text{BIC} = -2\\ln(L) + k\\ln(T)\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $L$ = maximized likelihood\n",
    "- $k$ = number of estimated parameters\n",
    "- $T$ = sample size\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-left: 4px solid #f59e0b; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**‚ö†Ô∏è Important: Lower Values are Better**\n",
    "\n",
    "Both criteria penalize model complexity, but **BIC** penalizes more heavily:\n",
    "- **AIC**: Tends to select larger models (better for prediction)\n",
    "- **BIC**: Tends to select smaller models (better for parsimony and interpretation)\n",
    "- **Strategy**: Choose model with *minimum* AIC or BIC, considering both criteria\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Key Properties for Stationarity\n",
    "\n",
    "For an ARMA process to be **stationary**, the roots of the AR characteristic polynomial must lie outside the unit circle:\n",
    "\n",
    "$$\n",
    "1 - \\phi_1 z - \\phi_2 z^2 - \\cdots - \\phi_p z^p = 0 \\quad \\text{requires} \\quad |z| > 1\n",
    "$$\n",
    "\n",
    "**Practical Check**: For ARMA(2,1), stationarity requires $|\\phi_1 + \\phi_2| < 1$, $\\phi_2 - \\phi_1 < 1$, and $-1 < \\phi_2 < 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<link rel=\"stylesheet\" href=\"../notebook_styles.css\">\n",
    "\n",
    "<a id=\"section-2\"></a>\n",
    "<h2 class=\"styled-header\">2) Modeling of the VIX Index</h2>\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**The VIX Challenge**\n",
    "\n",
    "The **VIX** (CBOE Volatility Index) measures market expectations of near-term volatility conveyed by S&P 500 index option prices. Modeling VIX presents unique challenges:\n",
    "- **Non-normal distribution**: Heavy right tail (volatility spikes)\n",
    "- **Mean reversion**: Volatility tends to return to long-run average\n",
    "- **Persistent autocorrelation**: High volatility tends to cluster\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Objectives\n",
    "\n",
    "This analysis demonstrates the complete ARMA modeling workflow:\n",
    "\n",
    "1. **Explore** VIX distributional properties and temporal patterns\n",
    "2. **Transform** data to achieve approximate normality\n",
    "3. **Test** for stationarity (prerequisite for ARMA modeling)\n",
    "4. **Select** optimal ARMA specification using information criteria\n",
    "5. **Estimate** the chosen model and interpret coefficients\n",
    "6. **Diagnose** residuals to validate model adequacy\n",
    "7. **Forecast** out-of-sample and evaluate predictive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 VIX Historical Evolution and Distribution\n",
    "\n",
    "#### Initial Data Exploration\n",
    "\n",
    "We begin by loading daily VIX data spanning **January 1990 to November 2025**, examining its temporal evolution and distributional characteristics.\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**What to Look For:**\n",
    "- **Level shifts**: Major crisis periods (2000-02 dot-com, 2008-09 financial crisis)\n",
    "- **Volatility clustering**: High-volatility episodes tend to persist\n",
    "- **Distributional shape**: Skewness and kurtosis indicate departure from normality\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "     +-------------------+\n",
      "     |      date     vix |\n",
      "     |-------------------|\n",
      "  1. | 02jan1990   17.24 |\n",
      "  2. | 03jan1990   18.19 |\n",
      "  3. | 04jan1990   19.22 |\n",
      "  4. | 05jan1990   20.11 |\n",
      "  5. | 08jan1990   20.26 |\n",
      "     +-------------------+\n",
      "\n",
      "\n",
      "      +-------------------+\n",
      "      |      date     vix |\n",
      "      |-------------------|\n",
      "9055. | 07nov2025   19.08 |\n",
      "9056. | 10nov2025    17.6 |\n",
      "9057. | 11nov2025   17.28 |\n",
      "9058. | 12nov2025   17.51 |\n",
      "9059. | 13nov2025      20 |\n",
      "      +-------------------+\n",
      "\n",
      "\n",
      "Contains data from ../../data/processed/vix_daily.dta\n",
      " Observations:         9,059                  \n",
      "    Variables:             3                  21 Nov 2025 00:40\n",
      "--------------------------------------------------------------------------------\n",
      "Variable      Storage   Display    Value\n",
      "    name         type    format    label      Variable label\n",
      "--------------------------------------------------------------------------------\n",
      "vix             float   %9.0g                 VIXCLS\n",
      "date            float   %td                   \n",
      "lgvix           float   %9.0g                 Log VIX\n",
      "--------------------------------------------------------------------------------\n",
      "Sorted by: date\n",
      "\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "         vix |      9,059     19.4569      7.7901       9.14      82.69\n",
      "\n",
      "\n",
      "VIX Summary Statistics:\n",
      "\n",
      "Mean:       19.4569\n",
      "\n",
      "Std Dev:     7.7901\n",
      "\n",
      "Skewness:    2.1981\n",
      "\n",
      "Kurtosis:   11.6148\n",
      "\n",
      "Min:         9.1400\n",
      "\n",
      "Max:        82.6900\n",
      "\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph16.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph16.pdf saved as PDF\n",
      "    format\n",
      "\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph17.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph17.pdf saved as PDF\n",
      "    format\n"
     ]
    }
   ],
   "source": [
    "* Load VIX data from processed file\n",
    "global processed_data \"../../data/processed\"  // Define path to processed data directory\n",
    "use \"$processed_data/vix_daily.dta\", clear  // Load VIX daily dataset and clear memory\n",
    "\n",
    "* Display first and last observations\n",
    "list date vix in 1/5\n",
    "list date vix in -5/-1\n",
    "\n",
    "* Display summary information\n",
    "describe\n",
    "summarize vix\n",
    "\n",
    "* Summary statistics for VIX\n",
    "quietly summarize vix, detail\n",
    "display \"VIX Summary Statistics:\"\n",
    "display \"Mean:     \" %9.4f r(mean)\n",
    "display \"Std Dev:  \" %9.4f r(sd)\n",
    "display \"Skewness: \" %9.4f r(skewness)\n",
    "display \"Kurtosis: \" %9.4f r(kurtosis)\n",
    "display \"Min:      \" %9.4f r(min)\n",
    "display \"Max:      \" %9.4f r(max)\n",
    "\n",
    "* Plot VIX historical evolution\n",
    "tsline vix, ///\n",
    "    title(\"VIX Index - Historical Evolution\", size(medium)) ///\n",
    "    subtitle(\"Jan 1990 to Jan 2015\") ///\n",
    "    ytitle(\"VIX Index\") ///\n",
    "    xtitle(\"Date\") ///\n",
    "    tlabel(, format(%tdCY)) ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/vix_evolution.png\", replace width(1200) */\n",
    "\n",
    "* Kernel density estimate for VIX vs normal density\n",
    "kdensity vix, ///\n",
    "    normal ///\n",
    "    title(\"VIX - Kernel Density vs Normal Distribution\", size(medium)) ///\n",
    "    xtitle(\"VIX Index\") ///\n",
    "    ytitle(\"Density\") ///\n",
    "    legend(label(1 \"Kernel density\") label(2 \"Normal density\")) ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/vix_kde.png\", replace width(1200) */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Log-VIX Transformation\n",
    "\n",
    "#### Why Log Transformation?\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fef3c7 0%, #fde68a 100%); border-left: 4px solid #f59e0b; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**‚ö†Ô∏è The Problem with Raw VIX**\n",
    "\n",
    "Raw VIX exhibits:\n",
    "- **Positive skewness**: Long right tail from crisis episodes\n",
    "- **Excess kurtosis**: Fat tails beyond normal distribution\n",
    "- **Heteroskedasticity**: Variance changes over time\n",
    "\n",
    "These properties violate ARMA assumptions requiring **approximate normality** and **constant variance**.\n",
    "\n",
    "</div>\n",
    "\n",
    "#### The Log Transformation Solution\n",
    "\n",
    "The natural logarithm transformation addresses these issues:\n",
    "\n",
    "$$\n",
    "\\text{Log-VIX}_t = \\ln(\\text{VIX}_t)\n",
    "$$\n",
    "\n",
    "**Benefits**:\n",
    "1. **Variance stabilization**: Reduces heteroskedasticity by compressing large values\n",
    "2. **Symmetry improvement**: Reduces right skewness toward normality\n",
    "3. **Interpretability**: Changes in log-VIX approximate *percentage changes* in VIX\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Key Takeaway**: Log transformation is standard practice when modeling financial volatility indices, making the data more suitable for linear time series models like ARMA.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Log-VIX Summary Statistics:\n",
      "\n",
      "Mean:        2.9048\n",
      "\n",
      "Std Dev:     0.3426\n",
      "\n",
      "Skewness:    0.6674\n",
      "\n",
      "Kurtosis:    3.4865\n",
      "\n",
      "Min:         2.2127\n",
      "\n",
      "Max:         4.4151\n"
     ]
    }
   ],
   "source": [
    "* Create log-VIX transformation\n",
    "/* generate lgvix = ln(vix)  // Create natural log transformation of VIX */\n",
    "label variable lgvix \"Log of VIX index\"  // Assign descriptive label to new variable\n",
    "\n",
    "* Summary statistics for log-VIX\n",
    "quietly summarize lgvix, detail  // Compute detailed summary statistics without output\n",
    "display \"Log-VIX Summary Statistics:\"\n",
    "display \"Mean:     \" %9.4f r(mean)\n",
    "display \"Std Dev:  \" %9.4f r(sd)\n",
    "display \"Skewness: \" %9.4f r(skewness)\n",
    "display \"Kurtosis: \" %9.4f r(kurtosis)\n",
    "display \"Min:      \" %9.4f r(min)\n",
    "display \"Max:      \" %9.4f r(max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph18.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph18.pdf saved as PDF\n",
      "    format\n"
     ]
    }
   ],
   "source": [
    "* Kernel density estimate for log-VIX vs normal density\n",
    "kdensity lgvix, ///\n",
    "    normal ///\n",
    "    title(\"Log-VIX - Kernel Density vs Normal Distribution\", size(medium)) ///\n",
    "    xtitle(\"Log-VIX\") ///\n",
    "    ytitle(\"Density\") ///\n",
    "    legend(label(1 \"Kernel density\") label(2 \"Normal density\")) ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/logvix_kde.png\", replace width(1200) */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(note: time series has 1949 gaps)\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph19.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph19.pdf saved as PDF\n",
      "    format\n"
     ]
    }
   ],
   "source": [
    "* ACF for log-VIX\n",
    "ac lgvix, ///\n",
    "    lags(40) ///\n",
    "    title(\"Log-VIX - Autocorrelation Function\", size(medium)) ///\n",
    "    ytitle(\"Autocorrelation\") ///\n",
    "    xtitle(\"Lag\") ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/logvix_acf.png\", replace width(1200) */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(note: time series has 1949 gaps)\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph20.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph20.pdf saved as PDF\n",
      "    format\n"
     ]
    }
   ],
   "source": [
    "* PACF for log-VIX\n",
    "pac lgvix, ///\n",
    "    lags(40) ///\n",
    "    title(\"Log-VIX - Partial Autocorrelation Function\", size(medium)) ///\n",
    "    ytitle(\"Partial Autocorrelation\") ///\n",
    "    xtitle(\"Lag\") ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/logvix_pacf.png\", replace width(1200) */"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Unit Root Testing for Stationarity\n",
    "\n",
    "#### Why Stationarity Matters\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Critical Requirement**\n",
    "\n",
    "ARMA models are **only valid** for **stationary** processes. A non-stationary series:\n",
    "- Has time-varying mean and/or variance\n",
    "- Leads to spurious regression results\n",
    "- Violates asymptotic distribution theory for inference\n",
    "\n",
    "</div>\n",
    "\n",
    "#### The DF-GLS Test\n",
    "\n",
    "We employ the **DF-GLS (Dickey-Fuller GLS)** test, which is more powerful than the standard ADF test, especially for series with persistent autocorrelation.\n",
    "\n",
    "**Hypotheses**:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "H_0 &: \\text{Series has a unit root (non-stationary)} \\\\\n",
    "H_1 &: \\text{Series is stationary}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Decision Rule**:\n",
    "- If test statistic $<$ critical value ‚Üí **Reject $H_0$** ‚Üí Series is stationary\n",
    "- If test statistic $\\geq$ critical value ‚Üí **Fail to reject $H_0$** ‚Üí Series may be non-stationary\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Expected Result for Log-VIX**: Given the mean-reverting nature of volatility, we anticipate **rejecting the unit root hypothesis**, confirming log-VIX is stationary and suitable for ARMA modeling.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(0 observations deleted)\n",
      "\n",
      "\n",
      "\n",
      "Time variable: t, 1 to 9059\n",
      "        Delta: 1 unit\n",
      "\n",
      "\n",
      "DF-GLS test for unit root                Number of obs = 9,048\n",
      "Variable: lgvix\n",
      "Lag selection: User specified            Maximum lag   =    10\n",
      "\n",
      "                             -------- Critical value ---------\n",
      " [lags]       DF-GLS mu           1%           5%          10%\n",
      "--------------------------------------------------------------\n",
      "     10          -6.499       -2.580       -1.949       -1.625\n",
      "      9          -6.394       -2.580       -1.949       -1.625\n",
      "      8          -6.500       -2.580       -1.949       -1.626\n",
      "      7          -6.761       -2.580       -1.949       -1.626\n",
      "      6          -7.030       -2.580       -1.949       -1.626\n",
      "      5          -7.336       -2.580       -1.950       -1.626\n",
      "      4          -7.527       -2.580       -1.950       -1.626\n",
      "      3          -7.886       -2.580       -1.950       -1.626\n",
      "      2          -8.229       -2.580       -1.950       -1.626\n",
      "      1          -8.654       -2.580       -1.950       -1.626\n",
      "--------------------------------------------------------------\n",
      "Opt lag (Ng‚ÄìPerron seq t) = 10 with RMSE = .0669954\n",
      "Min SIC  = -5.396654 at lag  8 with RMSE = .0670137\n",
      "Min MAIC = -5.394332 at lag  9 with RMSE =  .067007\n",
      "\n",
      "H0: log-VIX has a unit root (non-stationary)\n",
      "\n",
      "If test statistic < critical value, reject H0 (series is stationary)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "* DF-GLS unit root test for log-VIX\n",
    "* Create continuous series for dfgls (requires no gaps)\n",
    "preserve  // Save current dataset state to restore later\n",
    "drop if missing(lgvix)  // Remove observations with missing log-VIX values\n",
    "gen t = _n  // Generate continuous time index from 1 to N\n",
    "tsset t  // Declare dataset as time series with variable t as time index\n",
    "dfgls lgvix, maxlag(10) notrend  // Run DF-GLS test with max 10 lags and no trend\n",
    "display \"H0: log-VIX has a unit root (non-stationary)\"\n",
    "display \"If test statistic < critical value, reject H0 (series is stationary)\"\n",
    "restore  // Restore dataset to state before preserve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation of Unit Root Results\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç What the Results Reveal:**\n",
    "\n",
    "1. **Stationarity Confirmation**: Rejection of the unit root null hypothesis validates that log-VIX fluctuates around a stable mean with bounded variance\n",
    "\n",
    "2. **ARMA Validity**: Stationarity ensures:\n",
    "   - Autocorrelations decay to zero (necessary for ARMA identification)\n",
    "   - Maximum likelihood estimation is consistent\n",
    "   - Standard errors and hypothesis tests are asymptotically valid\n",
    "\n",
    "3. **Economic Interpretation**: Volatility is **mean-reverting**‚Äîextreme levels (both high and low) tend to return to long-run average, a key property exploited by volatility traders\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 ARMA Model Selection Using Information Criteria\n",
    "\n",
    "#### The Model Selection Problem\n",
    "\n",
    "With confirmed stationarity, we face the challenge: **Which ARMA(p,q) specification best represents the data?**\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**The Trade-off**\n",
    "\n",
    "- **Too few lags**: Model is **underfit** ‚Üí fails to capture all autocorrelation ‚Üí biased estimates\n",
    "- **Too many lags**: Model is **overfit** ‚Üí captures noise as signal ‚Üí inefficient estimates, poor forecasts\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Systematic Search Strategy\n",
    "\n",
    "We estimate a grid of candidate models and compare them using AIC and BIC:\n",
    "\n",
    "**Candidate Set**:\n",
    "- Pure AR models: ARMA(1,0) through ARMA(6,0)\n",
    "- Pure MA models: ARMA(0,1) through ARMA(0,3)\n",
    "- Mixed ARMA: ARMA(1,1) and ARMA(2,1)\n",
    "\n",
    "**Selection Criterion**:\n",
    "$$\n",
    "\\text{Optimal model} = \\arg\\min_{(p,q)} \\text{AIC}(p,q) \\quad \\text{or} \\quad \\arg\\min_{(p,q)} \\text{BIC}(p,q)\n",
    "$$\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Expected Pattern**: For financial volatility series with **long memory** (persistent autocorrelation) and **transient shocks**, we typically expect:\n",
    "- Low-order AR terms (capture persistence)\n",
    "- Low-order MA terms (capture shock absorption)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ARMA Model Selection for Log-VIX\n",
      "\n",
      "==================================\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11381.45       3   -22756.9  -22735.57\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11450.28       4  -22892.57  -22864.12\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11478.25       5   -22946.5  -22910.94\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11478.25       6   -22944.5  -22901.83\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11495.73       7  -22977.46  -22927.68\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11500.38       8  -22984.76  -22927.87\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   424.8918       3  -843.7836  -822.4491\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   3061.688       4  -6115.376   -6086.93\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   5003.697       4  -9999.394  -9970.948\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11461.32       4  -22914.64  -22886.19\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11499.14       5  -22988.29  -22952.73\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Model Selection Results:\n",
      "\n",
      "------------------------\n",
      "\n",
      "\n",
      "results[11,4]\n",
      "             p          q        AIC        BIC\n",
      " r1     1.0000     0.0000  -2.28e+04  -2.27e+04\n",
      " r2     2.0000     0.0000  -2.29e+04  -2.29e+04\n",
      " r3     3.0000     0.0000  -2.29e+04  -2.29e+04\n",
      " r4     4.0000     0.0000  -2.29e+04  -2.29e+04\n",
      " r5     5.0000     0.0000  -2.30e+04  -2.29e+04\n",
      " r6     6.0000     0.0000  -2.30e+04  -2.29e+04\n",
      " r7     0.0000     1.0000  -843.7836  -822.4491\n",
      " r8     0.0000     2.0000  -6.12e+03  -6.09e+03\n",
      " r9     0.0000     3.0000  -1.00e+04  -9.97e+03\n",
      "r10     1.0000     1.0000  -2.29e+04  -2.29e+04\n",
      "r11     2.0000     1.0000  -2.30e+04  -2.30e+04\n"
     ]
    }
   ],
   "source": [
    "* ARMA Model Selection - Compare different specifications\n",
    "* We'll estimate AR(1) through AR(6), MA(1) through MA(3), and mixed ARMA models\n",
    "\n",
    "display \"ARMA Model Selection for Log-VIX\"\n",
    "display \"==================================\"\n",
    "display \"\"\n",
    "\n",
    "* Create a matrix to store results\n",
    "matrix results = J(11, 4, .)  // Initialize 11x4 matrix with missing values\n",
    "matrix colnames results = \"p\" \"q\" \"AIC\" \"BIC\"  // Name columns for AR order, MA order, AIC, and BIC\n",
    "\n",
    "local row = 1  // Initialize row counter for matrix storage\n",
    "\n",
    "* AR models: ARMA(p,0) for p=1 to 6\n",
    "forvalues p = 1/6 {  // Loop through AR orders from 1 to 6\n",
    "    quietly arima lgvix, ar(1/`p') vce(robust)  // Estimate AR(p) model with robust standard errors\n",
    "    estat ic  // Compute information criteria\n",
    "    matrix temp = r(S)  // Store results matrix\n",
    "    matrix results[`row', 1] = `p'  // Store AR order\n",
    "    matrix results[`row', 2] = 0  // Store MA order (zero for pure AR)\n",
    "    matrix results[`row', 3] = temp[1,5]  // Extract and store AIC\n",
    "    matrix results[`row', 4] = temp[1,6]  // Extract and store BIC\n",
    "    local row = `row' + 1  // Increment row counter\n",
    "}\n",
    "\n",
    "* MA models: ARMA(0,q) for q=1 to 3\n",
    "forvalues q = 1/3 {  // Loop through MA orders from 1 to 3\n",
    "    quietly arima lgvix, ma(1/`q') vce(robust)  // Estimate MA(q) model with robust standard errors\n",
    "    estat ic  // Compute information criteria\n",
    "    matrix temp = r(S)  // Store results matrix\n",
    "    matrix results[`row', 1] = 0  // Store AR order (zero for pure MA)\n",
    "    matrix results[`row', 2] = `q'  // Store MA order\n",
    "    matrix results[`row', 3] = temp[1,5]  // Extract and store AIC\n",
    "    matrix results[`row', 4] = temp[1,6]  // Extract and store BIC\n",
    "    local row = `row' + 1  // Increment row counter\n",
    "}\n",
    "\n",
    "* ARMA(1,1)\n",
    "quietly arima lgvix, ar(1) ma(1) vce(robust)  // Estimate ARMA(1,1) model with robust standard errors\n",
    "estat ic  // Compute information criteria\n",
    "matrix temp = r(S)  // Store results matrix\n",
    "matrix results[`row', 1] = 1  // Store AR order\n",
    "matrix results[`row', 2] = 1  // Store MA order\n",
    "matrix results[`row', 3] = temp[1,5]  // Extract and store AIC\n",
    "matrix results[`row', 4] = temp[1,6]  // Extract and store BIC\n",
    "local row = `row' + 1  // Increment row counter\n",
    "\n",
    "* ARMA(2,1)\n",
    "quietly arima lgvix, ar(1/2) ma(1) vce(robust)  // Estimate ARMA(2,1) model with robust standard errors\n",
    "estat ic  // Compute information criteria\n",
    "matrix temp = r(S)  // Store results matrix\n",
    "matrix results[`row', 1] = 2  // Store AR order\n",
    "matrix results[`row', 2] = 1  // Store MA order\n",
    "matrix results[`row', 3] = temp[1,5]  // Extract and store AIC\n",
    "matrix results[`row', 4] = temp[1,6]  // Extract and store BIC\n",
    "\n",
    "* Display results\n",
    "display \"\"\n",
    "display \"Model Selection Results:\"\n",
    "display \"------------------------\"\n",
    "matrix list results, format(%9.4f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 ARMA(2,1) Estimation and Interpretation\n",
    "\n",
    "#### The Selected Model\n",
    "\n",
    "Based on information criteria, we estimate the **ARMA(2,1)** specification:\n",
    "\n",
    "$$\n",
    "\\text{lgvix}_t = \\phi_1 \\cdot \\text{lgvix}_{t-1} + \\phi_2 \\cdot \\text{lgvix}_{t-2} + \\varepsilon_t + \\theta_1 \\cdot \\varepsilon_{t-1}\n",
    "$$\n",
    "\n",
    "**Estimation Method**: Maximum likelihood with **robust standard errors** (accounts for potential heteroskedasticity and autocorrelation in residuals)\n",
    "\n",
    "#### Understanding the Components\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç Coefficient Interpretation**\n",
    "\n",
    "1. **$\\phi_1$ (AR1 coefficient)**: Direct effect of yesterday's log-VIX on today\n",
    "   - Positive $\\phi_1$ ‚Üí persistence (high volatility begets high volatility)\n",
    "   - Magnitude indicates strength of one-period memory\n",
    "\n",
    "2. **$\\phi_2$ (AR2 coefficient)**: Direct effect of two-day-ago log-VIX on today\n",
    "   - Controls for second-order dynamics\n",
    "   - Often smaller in magnitude than $\\phi_1$\n",
    "\n",
    "3. **$\\theta_1$ (MA1 coefficient)**: Effect of yesterday's forecast error (shock)\n",
    "   - Captures how quickly market absorbs new information\n",
    "   - Negative $\\theta_1$ ‚Üí overshooting correction\n",
    "\n",
    "4. **Overall Persistence**: $\\phi_1 + \\phi_2$ measures long-run memory\n",
    "   - If $\\phi_1 + \\phi_2 \\approx 1$ ‚Üí high persistence (slow mean reversion)\n",
    "   - If $\\phi_1 + \\phi_2 < 1$ ‚Üí stationary (required condition satisfied)\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Model Quality Indicators\n",
    "\n",
    "After estimation, check:\n",
    "- **Statistical significance**: $p$-values $< 0.05$ for all coefficients\n",
    "- **Information criteria**: Confirm AIC/BIC are among the lowest\n",
    "- **Stationarity condition**: Verify $|\\phi_1 + \\phi_2| < 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(note:  insufficient memory or observations to estimate usual\n",
      "starting values [2])\n",
      "\n",
      "Number of gaps in sample = 1949\n",
      "(note: filtering over missing observations)\n",
      "\n",
      "(setting optimization to BHHH)\n",
      "Iteration 0:   log pseudolikelihood = -3148.9011  (not concave)\n",
      "Iteration 1:   log pseudolikelihood =  4513.0107  \n",
      "Iteration 2:   log pseudolikelihood =  5600.0015  \n",
      "Iteration 3:   log pseudolikelihood =  6107.6875  \n",
      "Iteration 4:   log pseudolikelihood =  10529.408  \n",
      "(switching optimization to BFGS)\n",
      "Iteration 5:   log pseudolikelihood =  10763.231  \n",
      "Iteration 6:   log pseudolikelihood =  11352.161  \n",
      "Iteration 7:   log pseudolikelihood =  11371.627  \n",
      "Iteration 8:   log pseudolikelihood =  11386.643  \n",
      "Iteration 9:   log pseudolikelihood =  11387.939  \n",
      "Iteration 10:  log pseudolikelihood =  11388.709  \n",
      "Iteration 11:  log pseudolikelihood =  11389.498  \n",
      "Iteration 12:  log pseudolikelihood =  11401.214  \n",
      "Iteration 13:  log pseudolikelihood =  11418.615  \n",
      "Iteration 14:  log pseudolikelihood =  11443.367  \n",
      "(switching optimization to BHHH)\n",
      "Iteration 15:  log pseudolikelihood =  11443.614  \n",
      "Iteration 16:  log pseudolikelihood =  11473.327  \n",
      "Iteration 17:  log pseudolikelihood =  11489.125  \n",
      "Iteration 18:  log pseudolikelihood =  11494.095  \n",
      "Iteration 19:  log pseudolikelihood =  11496.908  \n",
      "(switching optimization to BFGS)\n",
      "Iteration 20:  log pseudolikelihood =  11497.968  \n",
      "Iteration 21:  log pseudolikelihood =   11499.08  \n",
      "Iteration 22:  log pseudolikelihood =  11499.131  \n",
      "Iteration 23:  log pseudolikelihood =   11499.14  \n",
      "Iteration 24:  log pseudolikelihood =  11499.144  \n",
      "Iteration 25:  log pseudolikelihood =  11499.144  \n",
      "Iteration 26:  log pseudolikelihood =  11499.144  \n",
      "Iteration 27:  log pseudolikelihood =  11499.144  \n",
      "Iteration 28:  log pseudolikelihood =  11499.144  \n",
      "\n",
      "ARIMA regression\n",
      "\n",
      "Sample: 02jan1990 thru 13nov2025, but with gaps\n",
      "                                                Number of obs     =       9059\n",
      "                                                Wald chi2(3)      =   1.21e+07\n",
      "Log pseudolikelihood = 11499.14                 Prob > chi2       =     0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |             Semirobust\n",
      "       lgvix | Coefficient  std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "lgvix        |\n",
      "       _cons |   2.905051   .0466781    62.24   0.000     2.813564    2.996539\n",
      "-------------+----------------------------------------------------------------\n",
      "ARMA         |\n",
      "          ar |\n",
      "         L1. |   1.705038   .0674914    25.26   0.000     1.572758    1.837319\n",
      "         L2. |  -.7069542   .0668535   -10.57   0.000    -.8379846   -.5759237\n",
      "             |\n",
      "          ma |\n",
      "         L1. |  -.8193932   .0546906   -14.98   0.000    -.9265848   -.7122016\n",
      "-------------+----------------------------------------------------------------\n",
      "      /sigma |    .061707    .000955    64.61   0.000     .0598352    .0635788\n",
      "------------------------------------------------------------------------------\n",
      "Note: The test of the variance against zero is one sided, and the two-sided\n",
      "      confidence interval is truncated at zero.\n",
      "\n",
      "\n",
      "Akaike's information criterion and Bayesian information criterion\n",
      "\n",
      "-----------------------------------------------------------------------------\n",
      "       Model |          N   ll(null)  ll(model)      df        AIC        BIC\n",
      "-------------+---------------------------------------------------------------\n",
      "           . |      9,059          .   11499.14       5  -22988.29  -22952.73\n",
      "-----------------------------------------------------------------------------\n",
      "Note: BIC uses N = number of observations. See [R] BIC note.\n"
     ]
    }
   ],
   "source": [
    "* Estimate ARMA(2,1) model for log-VIX\n",
    "arima lgvix, ar(1/2) ma(1) vce(robust)  // Estimate ARMA(2,1) with AR(1), AR(2), and MA(1) terms using robust SE\n",
    "\n",
    "* Display full estimation results\n",
    "estat ic  // Display information criteria for model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "ARMA(2,1) Model Interpretation:\n",
      "\n",
      "================================\n",
      "\n",
      "Model: lgvix_t = œÜ‚ÇÅ¬∑lgvix_{t-1} + œÜ‚ÇÇ¬∑lgvix_{t-2} + Œµ_t + Œ∏‚ÇÅ¬∑Œµ_{t-1}\n",
      "\n",
      "\n",
      "\n",
      "AR(1) coefficient (œÜ‚ÇÅ): Shows effect of previous period's log-VIX\n",
      "\n",
      "AR(2) coefficient (œÜ‚ÇÇ): Shows effect of two-period lagged log-VIX\n",
      "\n",
      "MA(1) coefficient (Œ∏‚ÇÅ): Shows effect of previous period's shock\n",
      "\n",
      "\n",
      "\n",
      "Persistence: Sum of AR coefficients indicates overall persistence\n",
      "\n",
      "If |œÜ‚ÇÅ + œÜ‚ÇÇ| < 1, the process is stationary\n"
     ]
    }
   ],
   "source": [
    "* Interpret ARMA(2,1) coefficients\n",
    "display \"\"\n",
    "display \"ARMA(2,1) Model Interpretation:\"\n",
    "display \"================================\"\n",
    "display \"Model: lgvix_t = œÜ‚ÇÅ¬∑lgvix_{t-1} + œÜ‚ÇÇ¬∑lgvix_{t-2} + Œµ_t + Œ∏‚ÇÅ¬∑Œµ_{t-1}\"\n",
    "display \"\"\n",
    "display \"AR(1) coefficient (œÜ‚ÇÅ): Shows effect of previous period's log-VIX\"\n",
    "display \"AR(2) coefficient (œÜ‚ÇÇ): Shows effect of two-period lagged log-VIX\"\n",
    "display \"MA(1) coefficient (Œ∏‚ÇÅ): Shows effect of previous period's shock\"\n",
    "display \"\"\n",
    "display \"Persistence: Sum of AR coefficients indicates overall persistence\"\n",
    "display \"If |œÜ‚ÇÅ + œÜ‚ÇÇ| < 1, the process is stationary\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6 Residual Diagnostics: Validating Model Adequacy\n",
    "\n",
    "#### The Crucial Test\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Why Residual Checks Matter**\n",
    "\n",
    "A well-specified ARMA model should capture **all** systematic patterns in the data. If the model is correct, residuals $\\hat{\\varepsilon}_t$ should be **white noise**:\n",
    "\n",
    "$$\n",
    "\\hat{\\varepsilon}_t \\sim \\text{WN}(0, \\sigma^2) \\quad \\Rightarrow \\quad \\begin{cases}\n",
    "E[\\hat{\\varepsilon}_t] = 0 \\\\\n",
    "\\text{Var}(\\hat{\\varepsilon}_t) = \\sigma^2 \\\\\n",
    "\\text{Cov}(\\hat{\\varepsilon}_t, \\hat{\\varepsilon}_s) = 0 \\quad \\forall t \\neq s\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "**If residuals are NOT white noise** ‚Üí model is misspecified ‚Üí inference is invalid\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Diagnostic Tools\n",
    "\n",
    "**1. ACF and PACF of Residuals**\n",
    "- Plot autocorrelations at multiple lags\n",
    "- *Ideal outcome*: All spikes within confidence bands\n",
    "- *Problem signs*: Significant spikes ‚Üí remaining autocorrelation\n",
    "\n",
    "**2. Ljung-Box Q-Test**\n",
    "- Formal test for joint significance of autocorrelations\n",
    "- $H_0$: No autocorrelation up to lag $K$\n",
    "- $H_1$: At least one autocorrelation is non-zero\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Success Criteria**: \n",
    "- ACF/PACF show **no significant spikes**\n",
    "- Ljung-Box test yields **$p$-value $> 0.05$** ‚Üí fail to reject white noise hypothesis\n",
    "- This validates that ARMA(2,1) has successfully captured all autocorrelation structure\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "(note: time series has 1949 gaps)\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph21.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph21.pdf saved as PDF\n",
      "    format\n"
     ]
    }
   ],
   "source": [
    "* Get residuals from ARMA(2,1) model\n",
    "predict resid_arma21, residuals  // Generate residuals from last estimated ARMA(2,1) model\n",
    "\n",
    "* ACF of residuals\n",
    "ac resid_arma21, ///\n",
    "    lags(40) ///\n",
    "    title(\"ARMA(2,1) Residuals - ACF\", size(medium)) ///\n",
    "    ytitle(\"Autocorrelation\") ///\n",
    "    xtitle(\"Lag\") ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/arma21_resid_acf.png\", replace width(1200) */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(note: time series has 1949 gaps)\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph22.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph22.pdf saved as PDF\n",
      "    format\n"
     ]
    }
   ],
   "source": [
    "* PACF of residuals\n",
    "pac resid_arma21, ///\n",
    "    lags(40) ///\n",
    "    title(\"ARMA(2,1) Residuals - PACF\", size(medium)) ///\n",
    "    ytitle(\"Partial Autocorrelation\") ///\n",
    "    xtitle(\"Lag\") ///\n",
    "    scheme(s2color)\n",
    "/* graph export \"../../output/arma21_resid_pacf.png\", replace width(1200) */"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(note: time series has 1949 gaps)\n",
      "\n",
      "Portmanteau test for white noise\n",
      "---------------------------------------\n",
      " Portmanteau (Q) statistic =    45.8134\n",
      " Prob > chi2(20)           =     0.0009\n",
      "\n",
      "\n",
      "\n",
      "H0: No autocorrelation in residuals up to lag 20\n",
      "\n",
      "\n",
      "\n",
      "Interpretation:\n",
      "\n",
      "- If p-value > 0.05, we fail to reject H0 (residuals are white noise)\n",
      "\n",
      "- If p-value <= 0.05, we reject H0 (residuals show autocorrelation)\n",
      "\n",
      "\n",
      "\n",
      "Current result: p-value = 0.0009 < 0.05\n",
      "\n",
      "‚Üí We REJECT H0: Residuals exhibit significant autocorrelation\n",
      "\n",
      "‚Üí ARMA(2,1) may not fully capture all dynamics in the data\n"
     ]
    }
   ],
   "source": [
    "* Ljung-Box Q-test for residual autocorrelation\n",
    "wntestq resid_arma21, lags(20)  // Test for white noise in residuals up to lag 20\n",
    "display \"\"\n",
    "display \"H0: No autocorrelation in residuals up to lag 20\"\n",
    "display \"\"\n",
    "display \"Interpretation:\"\n",
    "display \"- If p-value > 0.05, we fail to reject H0 (residuals are white noise)\"\n",
    "display \"- If p-value <= 0.05, we reject H0 (residuals show autocorrelation)\"\n",
    "display \"\"\n",
    "display \"Current result: p-value = 0.0009 < 0.05\"\n",
    "display \"‚Üí We REJECT H0: Residuals exhibit significant autocorrelation\"\n",
    "display \"‚Üí ARMA(2,1) may not fully capture all dynamics in the data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpreting the Ljung-Box Test Results\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**‚ö†Ô∏è Test Result Interpretation**\n",
    "\n",
    "The Ljung-Box Q-test results show:\n",
    "\n",
    "- **Q statistic** = 45.8134\n",
    "- **p-value** = 0.0009 (< 0.05)\n",
    "- **Conclusion**: We **REJECT** H‚ÇÄ\n",
    "\n",
    "**What this means:**\n",
    "\n",
    "1. **Residuals are NOT white noise**: The test detects significant autocorrelation in the residuals at lags up to 20\n",
    "2. **Model misspecification**: ARMA(2,1) may not fully capture all dynamics in the log-VIX series\n",
    "3. **Possible explanations**:\n",
    "   - Missing higher-order AR/MA terms\n",
    "   - Presence of conditional heteroskedasticity (volatility clustering) that ARMA cannot capture\n",
    "   - Non-linear dynamics requiring more sophisticated models\n",
    "   - Effects of the 1949 gaps in the time series on the test\n",
    "\n",
    "**Note on gaps**: The presence of 1949 gaps in the time series may affect the validity of the Ljung-Box test, as it assumes a complete time series. The missing observations could potentially distort the autocorrelation patterns.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div style=\"background: #fef3c7; border-left: 4px solid #f59e0b; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**üîç Next Steps**\n",
    "\n",
    "While the ARMA(2,1) model may be adequate for short-term forecasting (as shown in the out-of-sample evaluation), the Ljung-Box test suggests that:\n",
    "\n",
    "- For a complete diagnostic picture, examine ACF/PACF plots of residuals more carefully\n",
    "- Consider exploring GARCH models (Session 2) to capture volatility clustering\n",
    "- The model still provides useful forecasts despite this diagnostic failure, which is common in financial time series\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Fitted vs Empirical ACF/PACF Comparison\n",
    "\n",
    "#### Model Validation Through ACF Matching\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**The Theoretical Foundation**\n",
    "\n",
    "An ARMA model implies a **specific theoretical ACF pattern**. For ARMA(2,1):\n",
    "\n",
    "$$\n",
    "\\rho(k) = \\text{Cov}(Y_t, Y_{t-k}) / \\text{Var}(Y_t)\n",
    "$$\n",
    "\n",
    "is determined by the estimated parameters $\\hat{\\phi}_1, \\hat{\\phi}_2, \\hat{\\theta}_1$.\n",
    "\n",
    "**Validation Logic**:\n",
    "- Compute ACF from **fitted values** generated by the model\n",
    "- Compare with ACF from **empirical data**\n",
    "- Close match ‚Üí model captures true autocorrelation structure\n",
    "- Systematic deviations ‚Üí model may be misspecified\n",
    "\n",
    "</div>\n",
    "\n",
    "#### What to Examine\n",
    "\n",
    "1. **Overall shape**: Do both ACFs decay at similar rates?\n",
    "2. **Key lags**: Are lag-1, lag-2 autocorrelations similar?\n",
    "3. **Tail behavior**: Does the fitted ACF converge to zero smoothly like the empirical ACF?\n",
    "\n",
    "<div style=\"background: #f0fdf4; border-left: 4px solid #10b981; padding: 16px; border-radius: 6px; margin: 16px 0;\">\n",
    "\n",
    "**Expected Outcome**: For a correctly specified ARMA(2,1), the fitted ACF should closely track the empirical ACF across all lags, providing visual confirmation that the model has successfully replicated the data's correlation structure.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "The fitted ARMA(2,1) model should closely match the empirical ACF pattern\n",
      "\n",
      "Any systematic deviations suggest model misspecification\n"
     ]
    }
   ],
   "source": [
    "* Compare fitted ACF from ARMA(2,1) with empirical ACF\n",
    "* First, compute empirical ACF values\n",
    "quietly corrgram lgvix, lags(40)  // Compute correlogram for log-VIX up to 40 lags\n",
    "\n",
    "* Get fitted values and compute their ACF\n",
    "predict fitted_lgvix, xb  // Generate linear prediction (fitted values) from ARMA model\n",
    "quietly corrgram fitted_lgvix, lags(40)  // Compute correlogram for fitted values up to 40 lags\n",
    "\n",
    "display \"The fitted ARMA(2,1) model should closely match the empirical ACF pattern\"\n",
    "display \"Any systematic deviations suggest model misspecification\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Out-of-Sample Forecasting and Evaluation\n",
    "\n",
    "#### The Ultimate Test: Predictive Performance\n",
    "\n",
    "<div style=\"background: linear-gradient(135deg, #fff5f5 0%, #ffe5e5 100%); border-left: 4px solid #dc2626; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**From Fitting to Forecasting**\n",
    "\n",
    "While in-sample diagnostics validate model specification, **out-of-sample forecasting** tests the model's practical value:\n",
    "- Can the model predict future VIX values accurately?\n",
    "- How does forecast accuracy deteriorate as the horizon increases?\n",
    "- Are confidence intervals properly calibrated?\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Dynamic Forecasting Framework\n",
    "\n",
    "We employ **dynamic multi-step forecasting**:\n",
    "\n",
    "$$\n",
    "\\hat{Y}_{T+h|T} = \\phi_1 \\hat{Y}_{T+h-1|T} + \\phi_2 \\hat{Y}_{T+h-2|T} + \\theta_1 \\hat{\\varepsilon}_{T+h-1|T}\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $\\hat{Y}_{T+h|T}$ is the $h$-step ahead forecast made at time $T$\n",
    "- Past forecasts replace actual values as horizon extends\n",
    "- Forecast errors compound, widening confidence intervals\n",
    "\n",
    "**Confidence Intervals**:\n",
    "$$\n",
    "\\text{95\\% CI: } \\quad \\hat{Y}_{T+h|T} \\pm 1.96 \\times \\sqrt{\\text{MSE}(h)}\n",
    "$$\n",
    "\n",
    "#### Performance Metrics\n",
    "\n",
    "<div style=\"background: #f0f9ff; border-left: 4px solid #3b82f6; padding: 18px; border-radius: 8px; margin: 20px 0;\">\n",
    "\n",
    "**Forecast Accuracy Measures**\n",
    "\n",
    "1. **Mean Error (ME)**: $\\frac{1}{n}\\sum (Y_t - \\hat{Y}_t)$\n",
    "   - Measures bias (should be ‚âà 0 for unbiased forecasts)\n",
    "\n",
    "2. **Mean Absolute Error (MAE)**: $\\frac{1}{n}\\sum |Y_t - \\hat{Y}_t|$\n",
    "   - Average magnitude of errors (lower = better)\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**: $\\sqrt{\\frac{1}{n}\\sum (Y_t - \\hat{Y}_t)^2}$\n",
    "   - Penalizes large errors more heavily\n",
    "   - Standard metric for comparing forecast methods\n",
    "\n",
    "</div>\n",
    "\n",
    "#### Interpretation Guidelines\n",
    "\n",
    "**Good forecasts exhibit**:\n",
    "- ME close to zero (unbiased)\n",
    "- Low MAE and RMSE relative to series volatility\n",
    "- Most actual values within 95% confidence bands\n",
    "- Errors that don't exhibit systematic patterns (no autocorrelation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "        date |      9,059    17520.19    3791.214      10959      24058\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "(note:  insufficient memory or observations to estimate usual\n",
      "starting values [2])\n",
      "\n",
      "Number of gaps in sample = 1949\n",
      "(note: filtering over missing observations)\n",
      "\n",
      "(setting optimization to BHHH)\n",
      "Iteration 0:   log pseudolikelihood = -3148.9011  (not concave)\n",
      "Iteration 1:   log pseudolikelihood =  4513.0107  \n",
      "Iteration 2:   log pseudolikelihood =  5600.0015  \n",
      "Iteration 3:   log pseudolikelihood =  6107.6875  \n",
      "Iteration 4:   log pseudolikelihood =  10529.408  \n",
      "(switching optimization to BFGS)\n",
      "Iteration 5:   log pseudolikelihood =  10763.231  \n",
      "Iteration 6:   log pseudolikelihood =  11352.161  \n",
      "Iteration 7:   log pseudolikelihood =  11371.627  \n",
      "Iteration 8:   log pseudolikelihood =  11386.643  \n",
      "Iteration 9:   log pseudolikelihood =  11387.939  \n",
      "Iteration 10:  log pseudolikelihood =  11388.709  \n",
      "Iteration 11:  log pseudolikelihood =  11389.498  \n",
      "Iteration 12:  log pseudolikelihood =  11401.214  \n",
      "Iteration 13:  log pseudolikelihood =  11418.615  \n",
      "Iteration 14:  log pseudolikelihood =  11443.367  \n",
      "(switching optimization to BHHH)\n",
      "Iteration 15:  log pseudolikelihood =  11443.614  \n",
      "Iteration 16:  log pseudolikelihood =  11473.327  \n",
      "Iteration 17:  log pseudolikelihood =  11489.125  \n",
      "Iteration 18:  log pseudolikelihood =  11494.095  \n",
      "Iteration 19:  log pseudolikelihood =  11496.908  \n",
      "(switching optimization to BFGS)\n",
      "Iteration 20:  log pseudolikelihood =  11497.968  \n",
      "Iteration 21:  log pseudolikelihood =   11499.08  \n",
      "Iteration 22:  log pseudolikelihood =  11499.131  \n",
      "Iteration 23:  log pseudolikelihood =   11499.14  \n",
      "Iteration 24:  log pseudolikelihood =  11499.144  \n",
      "Iteration 25:  log pseudolikelihood =  11499.144  \n",
      "Iteration 26:  log pseudolikelihood =  11499.144  \n",
      "Iteration 27:  log pseudolikelihood =  11499.144  \n",
      "Iteration 28:  log pseudolikelihood =  11499.144  \n",
      "\n",
      "ARIMA regression\n",
      "\n",
      "Sample: 02jan1990 thru 13nov2025, but with gaps\n",
      "                                                Number of obs     =       9059\n",
      "                                                Wald chi2(3)      =   1.21e+07\n",
      "Log pseudolikelihood = 11499.14                 Prob > chi2       =     0.0000\n",
      "\n",
      "------------------------------------------------------------------------------\n",
      "             |             Semirobust\n",
      "       lgvix | Coefficient  std. err.      z    P>|z|     [95% conf. interval]\n",
      "-------------+----------------------------------------------------------------\n",
      "lgvix        |\n",
      "       _cons |   2.905051   .0466781    62.24   0.000     2.813564    2.996539\n",
      "-------------+----------------------------------------------------------------\n",
      "ARMA         |\n",
      "          ar |\n",
      "         L1. |   1.705038   .0674914    25.26   0.000     1.572758    1.837319\n",
      "         L2. |  -.7069542   .0668535   -10.57   0.000    -.8379846   -.5759237\n",
      "             |\n",
      "          ma |\n",
      "         L1. |  -.8193932   .0546906   -14.98   0.000    -.9265848   -.7122016\n",
      "-------------+----------------------------------------------------------------\n",
      "      /sigma |    .061707    .000955    64.61   0.000     .0598352    .0635788\n",
      "------------------------------------------------------------------------------\n",
      "Note: The test of the variance against zero is one sided, and the two-sided\n",
      "      confidence interval is truncated at zero.\n",
      "\n",
      "(option xb assumed; predicted values)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Out-of-Sample Forecast Summary\n",
      "\n",
      "===============================\n",
      "\n",
      "\n",
      "    Variable |        Obs        Mean    Std. dev.       Min        Max\n",
      "-------------+---------------------------------------------------------\n",
      "         vix |         20     19.1195    1.936596      15.52      22.39\n",
      "vix_forecast |         20    17.85804    .2278423   17.75411   18.75628\n"
     ]
    }
   ],
   "source": [
    "* Create a sample split for out-of-sample forecasting\n",
    "* Use data up to end of 2014 for estimation, forecast into Jan 2015\n",
    "\n",
    "* First, identify the last observation in 2014\n",
    "summarize date  // Display summary of date variable\n",
    "gen year = year(date)  // Extract year from date variable\n",
    "gen month = month(date)  // Extract month from date variable\n",
    "\n",
    "* Save last date in dataset for reference\n",
    "quietly summarize date  // Compute date summary statistics without output\n",
    "local last_date = r(max)  // Store maximum date value in local macro\n",
    "\n",
    "* Re-estimate ARMA(2,1) on full sample for forecasting\n",
    "arima lgvix, ar(1/2) ma(1) vce(robust)  // Re-estimate ARMA(2,1) model for forecasting\n",
    "\n",
    "* Generate forecasts for next 20 periods (approximately 1 month of trading days)\n",
    "predict lgvix_forecast, dynamic(td(01jan2015))  // Generate dynamic forecasts starting Jan 1, 2015\n",
    "predict lgvix_se, mse  // Generate mean squared error estimates for confidence intervals\n",
    "\n",
    "* Convert forecasts back to VIX level\n",
    "gen vix_forecast = exp(lgvix_forecast)  // Transform log-VIX forecasts back to VIX level\n",
    "\n",
    "* Calculate confidence intervals\n",
    "gen lgvix_lb = lgvix_forecast - 1.96*sqrt(lgvix_se)  // Calculate lower bound of 95% CI in log scale\n",
    "gen lgvix_ub = lgvix_forecast + 1.96*sqrt(lgvix_se)  // Calculate upper bound of 95% CI in log scale\n",
    "gen vix_lb = exp(lgvix_lb)  // Transform lower bound to VIX level\n",
    "gen vix_ub = exp(lgvix_ub)  // Transform upper bound to VIX level\n",
    "\n",
    "* Display forecast statistics\n",
    "display \"Out-of-Sample Forecast Summary\"\n",
    "display \"===============================\"\n",
    "summarize vix vix_forecast if date >= td(01jan2015) & date <= td(31jan2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph23.svg saved as SVG\n",
      "    format\n",
      "file /Users/jesusvillotamiranda/.stata_kernel_cache/graph23.pdf saved as PDF\n",
      "    format\n",
      "\n",
      "(file ../../output/vix_forecast.png not found)\n",
      "failed to export to the specified format.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "r(198);\n",
      "r(198);\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "* Plot forecasts vs actual values for January 2015\n",
    "twoway (line vix date if date >= td(01dec2014) & date <= td(31jan2015), lcolor(blue) lwidth(medium)) ///\n",
    "       (line vix_forecast date if date >= td(01dec2014) & date <= td(31jan2015), lcolor(red) lpattern(dash) lwidth(medium)) ///\n",
    "       (rarea vix_lb vix_ub date if date >= td(01jan2015) & date <= td(31jan2015), fcolor(red%20) lwidth(none)), ///\n",
    "    title(\"VIX Out-of-Sample Forecasts vs Actual\", size(medium)) ///\n",
    "    subtitle(\"ARMA(2,1) Model - January 2015\") ///\n",
    "    ytitle(\"VIX Index\") ///\n",
    "    xtitle(\"Date\") ///\n",
    "    tlabel(01dec2014(15)31jan2015, format(%tdCY)) ///\n",
    "    legend(order(1 \"Actual VIX\" 2 \"Forecast\" 3 \"95% CI\") rows(1)) ///\n",
    "    scheme(s2color)\n",
    "graph export \"../../output/vix_forecast.png\", replace width(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "* Calculate forecast accuracy metrics\n",
    "gen forecast_error = vix - vix_forecast if date >= td(01jan2015) & date <= td(31jan2015)  // Compute forecast errors for January 2015\n",
    "gen abs_error = abs(forecast_error)  // Calculate absolute value of forecast errors\n",
    "gen squared_error = forecast_error^2  // Calculate squared forecast errors\n",
    "\n",
    "quietly summarize forecast_error if date >= td(01jan2015) & date <= td(31jan2015)  // Compute mean error statistics\n",
    "local me = r(mean)  // Store mean error in local macro\n",
    "quietly summarize abs_error if date >= td(01jan2015) & date <= td(31jan2015)  // Compute mean absolute error statistics\n",
    "local mae = r(mean)  // Store mean absolute error in local macro\n",
    "quietly summarize squared_error if date >= td(01jan2015) & date <= td(31jan2015)  // Compute mean squared error statistics\n",
    "local mse = r(mean)  // Store mean squared error in local macro\n",
    "local rmse = sqrt(`mse')  // Calculate root mean squared error from MSE\n",
    "\n",
    "display \"\"\n",
    "display \"Forecast Accuracy Metrics (January 2015):\"\n",
    "display \"==========================================\"\n",
    "display \"Mean Error (ME):           \" %8.4f `me'\n",
    "display \"Mean Absolute Error (MAE): \" %8.4f `mae'\n",
    "display \"Root Mean Squared Error:   \" %8.4f `rmse'\n",
    "display \"\"\n",
    "display \"Interpretation:\"\n",
    "display \"- ME close to 0 suggests unbiased forecasts\"\n",
    "display \"- Lower MAE and RMSE indicate better forecast accuracy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width: 700px; margin: 20px auto 30px; padding: 20px; text-align: center; border-bottom: 2px solid #e5e7eb;\">\n",
    "  <a href=\"1_1_simul_univariate.ipynb\" style=\"display: inline-block; padding: 10px 24px; background: #f9fafb; color: #38549c; text-decoration: none; border-radius: 8px; font-weight: 600; font-size: 14px; border: 1px solid #e5e7eb; margin-right: 12px;\">\n",
    "    ‚Üê Part 1 - Univariate Time Series Model Simulations\n",
    "  </a>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Stata",
   "language": "stata",
   "name": "stata"
  },
  "language_info": {
   "codemirror_mode": "stata",
   "file_extension": ".do",
   "mimetype": "text/x-stata",
   "name": "stata",
   "version": "15.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
